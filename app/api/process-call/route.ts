import { NextResponse } from 'next/server';
import { createRouteHandlerClient } from '@supabase/auth-helpers-nextjs';
import { cookies } from 'next/headers';
import { Database } from '@/types/database.types';
import OpenAI from 'openai';
import { addCallLog } from '@/lib/addCallLog';

// ×”×’×“×¨×ª max duration ×œ×•×•×¨×¡×œ (5 ×“×§×•×ª ×œ××©×ª××©×™ Pro)
export const maxDuration = 300;

// ×‘×“×™×§×ª ××¤×ª×— OpenAI API ×¢× ×œ×•×’×™× ××¤×•×¨×˜×™×
const apiKey = process.env.OPENAI_API_KEY;
console.log('ğŸ” OpenAI API Key check:', {
  hasKey: !!apiKey,
  keyLength: apiKey?.length || 0,
  keyPrefix: apiKey?.substring(0, 10) + '...' || 'N/A',
  environment: process.env.NODE_ENV,
  vercelEnv: process.env.VERCEL_ENV
});

// ××ª×—×•×œ OpenAI API ×¢× ×‘×“×™×§×” ××©×•×¤×¨×ª
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY || '',
});

export async function POST(request: Request) {
  try {
    console.log('ğŸš€ Starting process-call function');
    const startTime = Date.now();
    
    // ×‘×“×™×§×ª ×–××™× ×•×ª ××¤×ª×— OpenAI ×¢× ×œ×•×’×™× ××¤×•×¨×˜×™×
    const apiKey = process.env.OPENAI_API_KEY;
    console.log('ğŸ” OpenAI API Key check:', {
      hasKey: !!apiKey,
      keyLength: apiKey?.length || 0,
      keyPrefix: apiKey?.substring(0, 10) + '...' || 'N/A',
      environment: process.env.NODE_ENV,
      vercelEnv: process.env.VERCEL_ENV,
      region: process.env.VERCEL_REGION || 'unknown'
    });

    if (!apiKey) {
      console.error('âŒ OPENAI_API_KEY ×œ× ××•×’×“×¨ ×‘×¤×•× ×§×¦×™×”');
      return NextResponse.json(
        { error: '××¤×ª×— OpenAI API ×œ× ××•×’×“×¨. ×× × ×‘×“×•×§ ××ª ××©×ª× ×™ ×”×¡×‘×™×‘×” ×‘-Vercel.' }, 
        { status: 500 }
      );
    }

    // ×™×¦×™×¨×ª ×œ×§×•×— ×¡×•×¤×”×‘×™×™×¡ ×‘×¦×“ ×”×©×¨×ª ×¢× ×”×¨×©××•×ª ××œ××•×ª
    const supabase = createRouteHandlerClient<Database>({ cookies });
    
    // ×§×‘×œ×ª ×”-ID ×©×œ ×”×©×™×—×” ××’×•×£ ×”×‘×§×©×”
    const { call_id } = await request.json();

    if (!call_id) {
      return NextResponse.json(
        { error: '×—×¡×¨ ××–×”×” ×©×™×—×” (call_id)' }, 
        { status: 400 }
      );
    }

    console.log(`ğŸ“ Processing call: ${call_id}`);
    await addCallLog(call_id, 'ğŸš€ ×”×ª×—×œ×ª ×ª×”×œ×™×š × ×™×ª×•×— ×©×™×—×”', { 
      timestamp: new Date().toISOString(),
      function_region: process.env.VERCEL_REGION || 'unknown',
      execution_start: startTime
    });

    // ×§×‘×œ×ª ×¤×¨×˜×™ ×”×©×™×—×”
    console.log('ğŸ“Š Fetching call data from Supabase');
    const { data: callData, error: callError } = await supabase
      .from('calls')
      .select('*')
      .eq('id', call_id)
      .single();

    if (callError || !callData) {
      console.error('âŒ Call not found:', callError);
      await addCallLog(call_id, 'âŒ ×©×’×™××” ×‘×˜×¢×™× ×ª ×”×©×™×—×”', { 
        error: callError, 
        error_message: callError?.message || '×©×’×™××” ×œ× ×™×“×•×¢×”' 
      });
      return NextResponse.json(
        { error: '×”×©×™×—×” ×œ× × ××¦××”', details: callError },
        { status: 404 }
      );
    }

    console.log('âœ… Call data loaded:', {
      call_type: callData.call_type,
      analysis_type: callData.analysis_type,
      audio_path: callData.audio_file_path
    });

    await addCallLog(call_id, 'âœ… × ×ª×•× ×™ ×©×™×—×” × ×˜×¢× ×• ×‘×”×¦×œ×—×”', { 
      call_type: callData.call_type,
      audio_path: callData.audio_file_path,
      analysis_type: callData.analysis_type
    });

    // ×¢×“×›×•×Ÿ ×¡×˜×˜×•×¡ ×”×¢×™×‘×•×“ ×œ-transcribing
    await supabase
      .from('calls')
      .update({ processing_status: 'transcribing' })
      .eq('id', call_id);

    await addCallLog(call_id, 'ğŸ”„ ×¢×“×›×•×Ÿ ×¡×˜×˜×•×¡ ×œ×ª××œ×•×œ', { new_status: 'transcribing' });

    // ×‘×“×™×§×ª ×¡×•×’ ×”× ×™×ª×•×—
    const isFullAnalysis = callData.analysis_type === 'full';
    await addCallLog(call_id, `â„¹ï¸ ×¡×•×’ × ×™×ª×•×—: ${isFullAnalysis ? '××œ× (×›×•×œ×œ ×ª××œ×•×œ)' : '×˜×•× ×¦×™×” ×‘×œ×‘×“'}`);

    // ×§×‘×œ×ª URL ×œ×”×•×¨×“×ª ×”×§×•×‘×¥
    if (!callData.audio_file_path) {
      console.error('âŒ Missing audio file path');
      await addCallLog(call_id, 'âŒ × ×ª×™×‘ ×§×•×‘×¥ ×”××•×“×™×• ×—×¡×¨', { 
        audio_path: callData.audio_file_path
      });
      return NextResponse.json(
        { error: '× ×ª×™×‘ ×§×•×‘×¥ ×”××•×“×™×• ×—×¡×¨' }, 
        { status: 400 }
      );
    }

    console.log('ğŸ”— Creating signed URL for audio file');
    const { data, error: getUrlError } = await supabase
      .storage
      .from('audio_files')
      .createSignedUrl(callData.audio_file_path, 60 * 5); // 5 ×“×§×•×ª

    const signedUrl = data?.signedUrl;
    
    if (getUrlError || !signedUrl) {
      console.error('âŒ Failed to get signed URL:', getUrlError);
      await addCallLog(call_id, 'âŒ ×©×’×™××” ×‘×§×‘×œ×ª ×§×™×©×•×¨ ×œ×§×•×‘×¥ ×”××•×“×™×•', { 
        error: getUrlError,
        error_message: getUrlError?.message || 'unknown',
        storage_path: callData.audio_file_path
      });
      await supabase
        .from('calls')
        .update({
          processing_status: 'error',
          error_message: `×©×’×™××” ×‘×§×‘×œ×ª ×§×•×‘×¥ ×”××•×“×™×•: ${getUrlError?.message || '××™×Ÿ URL ×—×ª×•×'}`
        })
        .eq('id', call_id);

      return NextResponse.json(
        { error: '×œ× × ×™×ª×Ÿ ×œ×§×‘×œ ××ª ×§×•×‘×¥ ×”××•×“×™×•', details: getUrlError },
        { status: 500 }
      );
    }

    console.log('âœ… Signed URL created successfully');
    await addCallLog(call_id, 'âœ… ×§×™×©×•×¨ ×”××•×“×™×• × ×•×¦×¨ ×‘×”×¦×œ×—×”', {
      url_expiry_minutes: 5,
      audio_path: callData.audio_file_path
    });

    // ×©×œ×‘ 1: ×ª××œ×•×œ ×”×©×™×—×” (×¨×§ ×¢×‘×•×¨ × ×™×ª×•×— ××œ×)
    let transcript = null;
    let transcriptSegments: any[] = [];
    let transcriptWords: any[] = [];
    
    if (isFullAnalysis) {
      try {
        console.log('ğŸ“ Starting transcription process');
        await addCallLog(call_id, 'ğŸ“ ××ª×—×™×œ ×ª×”×œ×™×š ×ª××œ×•×œ ×©×™×—×”', { model: 'whisper-1', language: 'he' });
        
        // ×”×•×¨×“×ª ×§×•×‘×¥ ×”××•×“×™×•
        console.log('â¬‡ï¸ Downloading audio file');
        await addCallLog(call_id, 'â¬‡ï¸ ××•×¨×™×“ ×§×•×‘×¥ ××•×“×™×• ××”×©×¨×ª');
        
        const audioResponse = await fetch(signedUrl, {
          method: 'GET',
          headers: {
            'User-Agent': 'OpenAI-Whisper-Client/1.0'
          }
        });
        
        if (!audioResponse.ok) {
          throw new Error(`×©×’×™××” ×‘×”×•×¨×“×ª ×§×•×‘×¥ ××•×“×™×•: ${audioResponse.status} ${audioResponse.statusText}`);
        }
        
        const audioBlob = await audioResponse.blob();
        
        console.log('âœ… Audio file downloaded:', {
          size_mb: (audioBlob.size / (1024 * 1024)).toFixed(2),
          type: audioBlob.type
        });
        
        await addCallLog(call_id, 'âœ… ×§×•×‘×¥ ××•×“×™×• ×”×•×¨×“ ×‘×”×¦×œ×—×”', { 
          size_bytes: audioBlob.size,
          size_mb: (audioBlob.size / (1024 * 1024)).toFixed(2),
          content_type: audioBlob.type
        });
        
        // ×”××¨×ª ×”-blob ×œ×§×•×‘×¥ ×©××¤×©×¨ ×œ×©×œ×•×— ×œ-OpenAI API
        const formData = new FormData();
        formData.append('file', audioBlob, 'audio.wav');
        formData.append('model', 'whisper-1');
        formData.append('language', 'he');
        formData.append('response_format', 'verbose_json');
        formData.append('timestamp_granularities[]', 'word');
        formData.append('timestamp_granularities[]', 'segment');
        
        console.log('ğŸ”„ Sending transcription request to Whisper API');
        await addCallLog(call_id, 'ğŸ”„ ×©×•×œ×— ×‘×§×©×ª ×ª××œ×•×œ ×œ-Whisper API', { 
          request_time: new Date().toISOString(),
          file_size_mb: (audioBlob.size / (1024 * 1024)).toFixed(2)
        });
        
        // ×× ×’× ×•×Ÿ × ×™×¡×™×•× ×•×ª ×—×•×–×¨×™× ×œ×§×¨×™××” ×œ-Whisper API
        const maxRetries = 3;
        let retryCount = 0;
        let transcriptionResponse;
        let transcriptionSuccess = false;
        
        while (retryCount < maxRetries && !transcriptionSuccess) {
          try {
            if (retryCount > 0) {
              // ×”×©×”×™×™×” ××§×¡×¤×•× × ×¦×™××œ×™×ª ×‘×™×Ÿ ×”× ×™×¡×™×•× ×•×ª (1s, 2s, 4s)
              const delayMs = Math.pow(2, retryCount - 1) * 1000;
              console.log(`â±ï¸ Waiting ${delayMs/1000}s before retry ${retryCount + 1}/${maxRetries}`);
              await addCallLog(call_id, `â±ï¸ ×××ª×™×Ÿ ${delayMs/1000} ×©× ×™×•×ª ×œ×¤× ×™ × ×™×¡×™×•×Ÿ ×—×•×–×¨ ${retryCount + 1}/${maxRetries}`);
              await new Promise(resolve => setTimeout(resolve, delayMs));
            }
            
            transcriptionResponse = await fetch('https://api.openai.com/v1/audio/transcriptions', {
              method: 'POST',
              headers: {
                'Authorization': `Bearer ${process.env.OPENAI_API_KEY || ''}`,
                'User-Agent': 'OpenAI-Whisper-Client/1.0'
              },
              body: formData
            });
            
            console.log('ğŸ“¡ Whisper API response received:', {
              status: transcriptionResponse.status,
              statusText: transcriptionResponse.statusText,
              ok: transcriptionResponse.ok,
              attempt: retryCount + 1
            });
            
            await addCallLog(call_id, 'ğŸ“¡ ×ª×©×•×‘×ª Whisper API ×”×ª×§×‘×œ×”', { 
              status: transcriptionResponse.status,
              statusText: transcriptionResponse.statusText,
              ok: transcriptionResponse.ok,
              attempt: retryCount + 1
            });
            
            if (transcriptionResponse.ok) {
              transcriptionSuccess = true;
              if (retryCount > 0) {
                console.log(`âœ… Retry attempt ${retryCount + 1} succeeded!`);
                await addCallLog(call_id, `âœ… × ×™×¡×™×•×Ÿ ×—×•×–×¨ ××¡×¤×¨ ${retryCount + 1} ×”×¦×œ×™×—!`);
              }
            } else {
              const errorText = await transcriptionResponse.text();
              console.error(`âŒ Whisper API error on attempt ${retryCount + 1}:`, {
                status: transcriptionResponse.status,
                error_text: errorText
              });
              await addCallLog(call_id, `âŒ ×©×’×™××ª Whisper API ×‘× ×™×¡×™×•×Ÿ ${retryCount + 1}`, { 
                status: transcriptionResponse.status,
                error_text: errorText
              });
              
              // ×× ×–×”×• × ×™×¡×™×•×Ÿ ××—×¨×•×Ÿ, ×–×¨×•×§ ×©×’×™××”
              if (retryCount === maxRetries - 1) {
                throw new Error(`Whisper API error: ${transcriptionResponse.status} ${errorText}`);
              }
            }
          } catch (fetchError: any) {
            console.error(`âŒ Network error on attempt ${retryCount + 1}:`, fetchError.message);
            await addCallLog(call_id, `âŒ ×©×’×™××ª ×ª×§×©×•×¨×ª ×‘× ×™×¡×™×•×Ÿ ${retryCount + 1}`, { error: fetchError.message });
            // ×× ×–×”×• × ×™×¡×™×•×Ÿ ××—×¨×•×Ÿ, ×–×¨×•×§ ×©×’×™××”
            if (retryCount === maxRetries - 1) {
              throw fetchError;
            }
          }
          
          retryCount++;
          
          // ×× ×”×¦×œ×™×—, ×¦× ××”×œ×•×œ××”
          if (transcriptionSuccess) break;
        }
        
        if (!transcriptionSuccess || !transcriptionResponse) {
          throw new Error(`×›×œ ${maxRetries} ×”× ×™×¡×™×•× ×•×ª ×œ×ª×§×©×¨ ×¢× Whisper API × ×›×©×œ×•`);
        }
        
        console.log('ğŸ“ Processing transcription response');
        const transcriptionData = await transcriptionResponse.json();
        transcript = transcriptionData.text;
        transcriptSegments = transcriptionData.segments || [];
        transcriptWords = transcriptionData.words || [];
        
        console.log('âœ… Transcription completed:', {
          transcript_length: transcript.length,
          transcript_words: transcript.split(' ').length,
          segments_count: transcriptSegments.length,
          words_with_timestamps: transcriptWords.length
        });
        
        await addCallLog(call_id, 'âœ… ×ª××œ×•×œ ×”×•×©×œ× ×‘×”×¦×œ×—×”', { 
          transcript_length: transcript.length,
          transcript_words: transcript.split(' ').length,
          segments_count: transcriptSegments.length,
          words_with_timestamps: transcriptWords.length,
          time_taken_ms: Date.now() - startTime
        });
        
        // ×¢×“×›×•×Ÿ ×”×ª××œ×™×œ ×‘×˜×‘×œ×” (×›×•×œ×œ ××™×“×¢ ××¤×•×¨×˜)
        await supabase
          .from('calls')
          .update({
            transcript,
            transcript_segments: transcriptSegments,
            transcript_words: transcriptWords,
            processing_status: 'analyzing_tone'
          })
          .eq('id', call_id);
          
        await addCallLog(call_id, 'ğŸ’¾ ×ª××œ×™×œ × ×©××¨ ×‘×”×¦×œ×—×” ×‘××¡×“ ×”× ×ª×•× ×™×', {
          new_status: 'analyzing_tone'
        });
          
      } catch (transcribeError: any) {
        console.error('âŒ Transcription error:', transcribeError);
        await addCallLog(call_id, 'âŒ ×©×’×™××” ×‘×ª××œ×•×œ', { 
          error: transcribeError.message,
          error_name: transcribeError.name,
          error_stack: transcribeError.stack?.substring(0, 200)
        });
        
        // ×¢×“×›×•×Ÿ ×”×¡×˜×˜×•×¡ ×œ×©×’×™××ª ×ª××œ×•×œ ××‘×œ × ×™×¡×™×•×Ÿ ×œ×”××©×™×š ×œ× ×™×ª×•×— ×˜×•× ××œ×™
        await supabase
          .from('calls')
          .update({
            processing_status: 'analyzing_tone',
            error_message: `×©×’×™××ª ×ª××œ×•×œ: ${transcribeError.message}. ×××©×™×š ×œ× ×™×ª×•×— ×˜×•× ××œ×™ ×‘×œ×‘×“.`
          })
          .eq('id', call_id);

        await addCallLog(call_id, 'âš ï¸ ×”×ª××œ×•×œ × ×›×©×œ, ×××©×™×š ×œ× ×™×ª×•×— ×˜×•× ××œ×™ ×‘×œ×‘×“', {
          transcription_status: 'failed',
          continuing_with: 'tone_analysis_only'
        });
        
        // ×‘××§×•× ×œ×”×¤×¡×™×§ ××ª ×”×ª×”×œ×™×š, × ××©×™×š ×œ× ×™×ª×•×— ×˜×•× ××œ×™ ×œ×œ× ×ª××œ×•×œ
        transcript = null;
      }
    } else {
      // ×× ×–×” × ×™×ª×•×— ×˜×•× ×¦×™×” ×‘×œ×‘×“, ×¢×“×›×•×Ÿ ×”×¡×˜×˜×•×¡ ×™×©×™×¨×•×ª ×œ-analyzing_tone
      await supabase
        .from('calls')
        .update({ processing_status: 'analyzing_tone' })
        .eq('id', call_id);
        
        await addCallLog(call_id, 'â© ×“×™×œ×•×’ ×¢×œ ×©×œ×‘ ×”×ª××œ×•×œ (× ×™×ª×•×— ×˜×•× ×¦×™×” ×‘×œ×‘×“)', {
          new_status: 'analyzing_tone'
        });
    }

    // ×©×œ×‘ 2: × ×™×ª×•×— ×˜×•×Ÿ ×™×©×™×¨ ××”××•×“×™×• ×¢× GPT-4o
    try {
      console.log('ğŸ­ Starting tone analysis');
      await addCallLog(call_id, 'ğŸ­ ××ª×—×™×œ × ×™×ª×•×— ×˜×•× ×¦×™×”', { model: 'gpt-4o' });
      
      // ×”×›× ×ª ×”×‘×§×©×” ×œ× ×™×ª×•×— ×˜×•× ×¦×™×”
      await addCallLog(call_id, 'ğŸ”„ ××›×™×Ÿ ×‘×§×©×” ×œ× ×™×ª×•×— ×˜×•× ×¦×™×” ×¢× GPT-4o');
      
      console.log('ğŸ”„ Sending tone analysis request to OpenAI');
      const toneAnalysisResponse = await openai.chat.completions.create({
        model: 'gpt-4o',
        messages: [
          {
            role: 'system',
            content: `××ª×” ××•××—×” ×‘× ×™×ª×•×— ×˜×•×Ÿ, ×¨×’×© ×•×¤×¨×•×–×•×“×™×” ×‘×©×™×—×•×ª ×˜×œ×¤×•× ×™×•×ª ×‘×¢×‘×¨×™×ª. 
            ×”×ª×¤×§×™×“ ×©×œ×š ×”×•× ×œ× ×ª×— ×‘××•×¤×Ÿ ××“×•×™×§ ××ª ×”×˜×•×Ÿ ×”×¨×’×©×™, ××™×›×•×ª ×”×§×•×œ, ×§×¦×‘ ×”×“×™×‘×•×¨, ×•××ª ×”×¤×¨×•×–×•×“×™×” ×”×›×œ×œ×™×ª ×©×œ ×”×“×•×‘×¨.
            
            ××ª×” ×× ×ª×—:
            1. ×˜×•×Ÿ ×¨×’×©×™ (×—×™×•×‘×™/×©×œ×™×œ×™/× ×™×™×˜×¨×œ×™, ×™×“×™×“×•×ª×™/×§×¨/××’×¨×¡×™×‘×™)
            2. ×¨××ª ×× ×¨×’×™×” (× ××•×›×”/×‘×™× ×•× ×™×ª/×’×‘×•×”×”)
            3. ××§×¦×•×¢×™×•×ª (×¨××” ×’×‘×•×”×”/×‘×™× ×•× ×™×ª/× ××•×›×”)
            4. ×—×™×•×‘×™×•×ª ×›×œ×œ×™×ª
            5. ×–×™×”×•×™ ×“×’×œ×™× ××“×•××™× (×¦×¢×§×•×ª, ×œ×—×¥, ×—×•×¡×¨ ×¡×‘×œ× ×•×ª, ××’×¨×¡×™×‘×™×•×ª)
            6. × ×™×ª×•×— ×¤×¨×•×–×•×“×™ ××¤×•×¨×˜ (×§×¦×‘, ×”×¤×¡×§×•×ª, ×¢×•×¦××”, ×”×˜××¢×•×ª)
            
            ×”×—×–×¨ ×ª××™×“ JSON ×‘××‘× ×” ×§×‘×•×¢:
            {
              "×˜×•×Ÿ_×›×œ×œ×™": "×ª×™××•×¨ ×”×˜×•×Ÿ ×”×›×œ×œ×™ ×©×œ ×”×©×™×—×”",
              "×¨××ª_×× ×¨×’×™×”": "×ª×™××•×¨ ×¨××ª ×”×× ×¨×’×™×”",
              "××§×¦×•×¢×™×•×ª": "×”×¢×¨×›×ª ×¨××ª ×”××§×¦×•×¢×™×•×ª",
              "×—×™×•×‘×™×•×ª": "×”×¢×¨×›×ª ×¨××ª ×”×—×™×•×‘×™×•×ª",
              "×“×’×œ×™×_××“×•××™×": {
                "×¦×¢×§×•×ª_×–×•×”×•": boolean,
                "×œ×—×¥_×’×‘×•×”": boolean,
                "×—×•×¡×¨_×¡×‘×œ× ×•×ª": boolean,
                "××’×¨×¡×™×‘×™×•×ª": boolean,
                "×˜×•×Ÿ_×œ×_××§×¦×•×¢×™": boolean
              },
              "× ×™×ª×•×—_×¤×¨×•×–×•×“×™": "× ×™×ª×•×— ××¤×•×¨×˜ ×©×œ ×§×¦×‘ ×“×™×‘×•×¨, ×”×¤×¡×§×•×ª, ×¢×•×¦××” ×•×”×˜××¢×•×ª",
              "×¦×™×•×Ÿ_×˜×•× ×¦×™×”": number, // ×¦×™×•×Ÿ ×‘×™×Ÿ 1-10
              "×”××œ×¦×•×ª_×©×™×¤×•×¨": ["×¨×©×™××” ×©×œ ×”××œ×¦×•×ª ×œ×©×™×¤×•×¨ ×”×˜×•×Ÿ ×•×”××§×¦×•×¢×™×•×ª"],
              "× ×§×•×“×•×ª_×—×•×–×§_×˜×•× ×œ×™×•×ª": ["×¨×©×™××” ×©×œ × ×§×•×“×•×ª ×—×•×–×§ ×‘×˜×•×Ÿ ×•×‘××•×¤×Ÿ ×”×ª×§×©×•×¨×ª"]
            }`
          },
          {
            role: 'user',
            content: `× ×ª×— ××ª ×”×˜×•×Ÿ, ×”×× ×¨×’×™×”, ×”××§×¦×•×¢×™×•×ª ×•×”×¤×¨×•×–×•×“×™×” ×©×œ ×”×©×™×—×” ×”×‘××”.
            ×–×”×” ×“×’×œ×™× ××“×•××™× ×•×¡×¤×§ ×”××œ×¦×•×ª ××§×¦×•×¢×™×•×ª ×œ×©×™×¤×•×¨.
            
            ×¡×•×’ ×”×©×™×—×”: ${callData.call_type}
            ${transcript ? `×ª××œ×™×œ ×”×©×™×—×”: ${transcript}` : '×œ× ×§×™×™× ×ª××œ×™×œ ×–××™×Ÿ. ×× × × ×ª×— ××ª ×”×˜×•× ×¦×™×” ×•×¨××ª ×”×× ×¨×’×™×” ×¨×§ ××”××•×“×™×•.'}
            ${!transcript ? '×©×™× ×œ×‘: ×”×ª××œ×•×œ × ×›×©×œ, ×œ×›×Ÿ ×× × ×”×ª××§×“ ×‘× ×™×ª×•×— ×˜×•× ××œ×™ ××”××•×“×™×• ×‘×œ×‘×“ ×•×‘×–×™×”×•×™ ×“×’×œ×™× ××“×•××™× ××§×•×¡×˜×™×™×.' : ''}
            
            ×”×§×¤×“ ×œ×”×—×–×™×¨ ××ª ×”×ª×©×•×‘×” ×‘×¤×•×¨××˜ JSON ×”××“×•×™×§ ×©×¦×•×™×Ÿ ×œ××¢×œ×”.`
          }
        ],
        response_format: { type: 'json_object' }
      });

      console.log('âœ… Tone analysis response received from OpenAI');
      await addCallLog(call_id, 'âœ… ×ª×©×•×‘×ª OpenAI ×”×ª×§×‘×œ×” ×œ× ×™×ª×•×— ×˜×•× ×¦×™×”', { 
        token_usage: toneAnalysisResponse.usage,
        model: toneAnalysisResponse.model,
        response_id: toneAnalysisResponse.id
      });

      const toneAnalysisReport = JSON.parse(toneAnalysisResponse.choices[0].message.content || '{}');
      
      console.log('âœ… Tone analysis completed');
      await addCallLog(call_id, 'âœ… × ×™×ª×•×— ×˜×•× ×¦×™×” ×”×•×©×œ×', { 
        report_keys: Object.keys(toneAnalysisReport),
        identified_red_flags: toneAnalysisReport.×“×’×œ×™×_××“×•××™× ? Object.keys(toneAnalysisReport.×“×’×œ×™×_××“×•××™×).filter(flag => toneAnalysisReport.×“×’×œ×™×_××“×•××™×[flag]) : []
      });

      // × ×™×ª×•×— ××œ× ×“×•×¨×© ×©×œ×‘ × ×•×¡×£
      if (isFullAnalysis) {
        // ×¢×“×›×•×Ÿ ×œ×©×œ×‘ analyzing_content
        await supabase
          .from('calls')
          .update({
            processing_status: 'analyzing_content'
          })
          .eq('id', call_id);

        await addCallLog(call_id, 'ğŸ”„ ×¢×“×›×•×Ÿ ×¡×˜×˜×•×¡ ×œ× ×™×ª×•×— ×ª×•×›×Ÿ', { new_status: 'analyzing_content' });
        console.log('ğŸ“Š Starting content analysis');
        await addCallLog(call_id, 'ğŸ“Š ××ª×—×™×œ × ×™×ª×•×— ×ª×•×›×Ÿ', { model: 'gpt-4-turbo' });

        // ×©×œ×‘ 3: × ×™×ª×•×— ×ª×•×›×Ÿ ××§×¦×•×¢×™ ×¢× GPT-4 Turbo
        // ×§×‘×œ×ª ×”×¤×¨×•××¤×˜ ×”××ª××™× ×œ×¡×•×’ ×”×©×™×—×”
        const { data: promptData, error: promptError } = await supabase
          .from('prompts')
          .select('system_prompt')
          .eq('call_type', callData.call_type)
          .single();

        let systemPrompt = '';
        if (promptError || !promptData) {
          console.log('âš ï¸ Using default prompt (prompt not found for call type)');
          await addCallLog(call_id, 'âš ï¸ ××©×ª××© ×‘×¤×¨×•××¤×˜ ×‘×¨×™×¨×ª ××—×“×œ', { 
            call_type: callData.call_type, 
            prompt_error: promptError?.message 
          });
          
          systemPrompt = `××ª×” ××•××—×” ×‘× ×™×ª×•×— ×©×™×—×•×ª ××›×™×¨×” ×•×©×™×¨×•×ª ×œ×§×•×—×•×ª ×‘×¢×‘×¨×™×ª.
          ×ª×¤×§×™×“×š ×œ× ×ª×— ×©×™×—×•×ª ×‘××•×¤×Ÿ ××¢××™×§ ×•×œ×¡×¤×§ ××©×•×‘ ××§×¦×•×¢×™.
          
          ×× × × ×ª×— ××ª ×”×©×™×—×” ×”×‘××” ×•×ª×Ÿ ×¦×™×•×Ÿ ×›×œ×œ×™ (1-10), ×–×”×” × ×§×•×“×•×ª ×—×•×–×§ ×•×—×•×œ×©×”,
          ×•×¡×¤×§ ×”××œ×¦×•×ª ××¢×©×™×•×ª ×œ×©×™×¤×•×¨.
          
          ×”×—×–×¨ ××ª ×”×ª×•×¦××•×ª ×‘×¤×•×¨××˜ JSON ×¢× ×”×©×“×•×ª ×”×‘××™×:
          {
            "overall_score": number,
            "red_flag": boolean,
            "executive_summary": "×¡×™×›×•× ×× ×”×œ×™× ×§×¦×¨",
            "strengths_and_preservation_points": ["× ×§×•×“×•×ª ×—×•×–×§"],
            "improvement_points": ["× ×§×•×“×•×ª ×œ×©×™×¤×•×¨"],
            "practical_recommendations": ["×”××œ×¦×•×ª ××¢×©×™×•×ª"],
            "segment_quotes": [{"text": "×¦×™×˜×•×˜", "comment": "×”×¢×¨×”", "category": "×§×˜×’×•×¨×™×”"}]
          }`;
        } else {
          systemPrompt = promptData.system_prompt;
          await addCallLog(call_id, 'âœ… ×¤×¨×•××¤×˜ ××•×ª×× × ×˜×¢×Ÿ ×‘×”×¦×œ×—×”', { 
            call_type: callData.call_type
          });
        }

        console.log('ğŸ”„ Sending content analysis request to OpenAI');
        const contentAnalysisResponse = await openai.chat.completions.create({
          model: 'gpt-4-turbo',
          messages: [
            {
              role: 'system',
              content: systemPrompt
            },
            {
              role: 'user',
              content: `× ×ª×— ××ª ×”×©×™×—×” ×”×‘××”:
              
              ×¡×•×’ ×”×©×™×—×”: ${callData.call_type}
              ×ª××œ×™×œ: ${transcript || '×œ× ×–××™×Ÿ'}
              ${callData.analysis_notes ? `×¤×¨××˜×¨×™× ××™×•×—×“×™× ×œ× ×™×ª×•×—: ${callData.analysis_notes}` : ''}
              
              ×”× ×—×™×•×ª × ×•×¡×¤×•×ª:
              1. ×›×œ×•×œ ×‘× ×™×ª×•×— ×¦×™×˜×•×˜×™× ×¨×œ×•×•× ×˜×™×™× ××”×©×™×—×” ×ª×—×ª ×©×“×” '×¦×™×˜×•×˜×™×' ××• '×§×˜×¢×™×_×¨×œ×•×•× ×˜×™×™×' 
              2. ×¢×‘×•×¨ ×›×œ ×¤×¨××˜×¨ ×©×‘×• × ××¦××• ×‘×¢×™×•×ª, ×”×•×¡×£ ×¦×™×˜×•×˜×™× ×¡×¤×¦×™×¤×™×™× ××”×©×™×—×” ×”××“×’×™××™× ××ª ×”×‘×¢×™×”
              3. ×œ×›×œ ×¦×™×˜×•×˜, × ×¡×” ×œ×¡×¤×§ ×’× timestamp_seconds ××“×•×™×§ ×‘×”×ª×‘×¡×¡ ×¢×œ ××™×“×¢ ×”×–×× ×™× ×©×¡×•×¤×§
              4. ×”×¦×¢ ×—×œ×•×¤×•×ª ××™×œ×•×œ×™×•×ª ×œ×›×œ ×¦×™×˜×•×˜ ×‘×¢×™×™×ª×™
              5. ×¤×•×¨××˜ ×”×¦×™×˜×•×˜: {"text": "×”×¦×™×˜×•×˜", "timestamp_seconds": ××¡×¤×¨, "comment": "×”×¢×¨×”", "category": "×§×˜×’×•×¨×™×”"}
              ${callData.analysis_notes ? '6. ×•×•×“× ×©×”× ×™×ª×•×— ××ª×™×™×—×¡ ×œ×¤×¨××˜×¨×™× ×”××™×•×—×“×™× ×©×¦×•×™× ×• ×œ××¢×œ×”' : ''}
              
              × ×™×ª×•×— ×˜×•× ×¦×™×”: ${JSON.stringify(toneAnalysisReport)}
              ×”×§×¤×“ ×œ×”×—×–×™×¨ ××ª ×”×ª×©×•×‘×” ×‘×¤×•×¨××˜ JSON.`
            }
          ],
          response_format: { type: 'json_object' }
        });

        console.log('âœ… Content analysis response received from OpenAI');
        await addCallLog(call_id, 'âœ… ×ª×©×•×‘×ª OpenAI ×”×ª×§×‘×œ×” ×œ× ×™×ª×•×— ×ª×•×›×Ÿ', { 
          token_usage: contentAnalysisResponse.usage,
          model: contentAnalysisResponse.model,
          response_id: contentAnalysisResponse.id,
          completion_time: new Date().toISOString()
        });

        const contentAnalysisReport = JSON.parse(contentAnalysisResponse.choices[0].message.content || '{}');
        
        console.log('âœ… Content analysis completed');
        await addCallLog(call_id, 'âœ… × ×™×ª×•×— ×ª×•×›×Ÿ ×”×•×©×œ×', { 
          overall_score: contentAnalysisReport.overall_score,
          report_sections: Object.keys(contentAnalysisReport),
          identified_strengths: contentAnalysisReport.strengths_and_preservation_points?.length || 0,
          improvement_points: contentAnalysisReport.improvement_points?.length || 0,
          has_red_flags: contentAnalysisReport.red_flag || false
        });

        // ×©×™×œ×•×‘ ×”× ×™×ª×•×—×™×
        const finalReport = {
          ...contentAnalysisReport,
          tone_analysis_report: toneAnalysisReport
        };

        // ×¢×“×›×•×Ÿ ×”× ×™×ª×•×— ×”×¡×•×¤×™ ×‘×˜×‘×œ×”
        await supabase
          .from('calls')
          .update({
            analysis_report: finalReport,
            tone_analysis_report: toneAnalysisReport,
            overall_score: contentAnalysisReport.overall_score || 0,
            red_flag: contentAnalysisReport.red_flag || false,
            processing_status: 'completed',
            analyzed_at: new Date().toISOString()
          })
          .eq('id', call_id);
          
        console.log('ğŸ Full analysis completed');
        await addCallLog(call_id, 'ğŸ × ×™×ª×•×— ×©×™×—×” ×”×•×©×œ×', { 
          overall_score: contentAnalysisReport.overall_score,
          red_flag: contentAnalysisReport.red_flag || false,
          completion_time: new Date().toISOString(),
          time_taken_seconds: Math.round((Date.now() - startTime) / 1000)
        });
          
      } else {
        // ×¨×§ × ×™×ª×•×— ×˜×•× ×¦×™×” - ×¢×“×›×•×Ÿ ×”× ×™×ª×•×— ×‘×˜×‘×œ×”
        const finalReport = {
          tone_analysis_report: toneAnalysisReport,
          // ×¢×‘×•×¨ × ×™×ª×•×— ×˜×•× ×¦×™×” ×‘×œ×‘×“, × ×©×ª××© ×‘×©×“×•×ª summary
          executive_summary: toneAnalysisReport.summary || '',
          overall_score: toneAnalysisReport.×¦×™×•×Ÿ_×˜×•× ×¦×™×” || 0,
          red_flag: toneAnalysisReport.×“×’×œ×™×_××“×•××™×?.×¦×¢×§×•×ª_×–×•×”×• || 
                  toneAnalysisReport.×“×’×œ×™×_××“×•××™×?.×œ×—×¥_×’×‘×•×” || 
                  toneAnalysisReport.×“×’×œ×™×_××“×•××™×?.×—×•×¡×¨_×¡×‘×œ× ×•×ª || false,
          strengths_and_preservation_points: toneAnalysisReport.× ×§×•×“×•×ª_×—×•×–×§_×˜×•× ×œ×™×•×ª || [],
          improvement_points: toneAnalysisReport.×”××œ×¦×•×ª_×©×™×¤×•×¨ || []
        };

        await supabase
          .from('calls')
          .update({
            analysis_report: finalReport,
            tone_analysis_report: toneAnalysisReport,
            overall_score: finalReport.overall_score,
            red_flag: finalReport.red_flag,
            processing_status: 'completed',
            analyzed_at: new Date().toISOString()
          })
          .eq('id', call_id);
          
        console.log('ğŸ Tone-only analysis completed');
        await addCallLog(call_id, 'ğŸ × ×™×ª×•×— ×˜×•× ×¦×™×” ×”×•×©×œ× (×¡×•×’ × ×™×ª×•×—: ×˜×•× ×¦×™×” ×‘×œ×‘×“)', { 
          overall_score: finalReport.overall_score,
          red_flag: finalReport.red_flag || false,
          completion_time: new Date().toISOString(),
          time_taken_seconds: Math.round((Date.now() - startTime) / 1000)
        });
      }

    } catch (analysisError: any) {
      console.error('âŒ Analysis error:', analysisError);
      await addCallLog(call_id, 'âŒ ×©×’×™××” ×‘× ×™×ª×•×—', { 
        error: analysisError.message,
        error_name: analysisError.name,
        error_stack: analysisError.stack?.substring(0, 200),
        error_time: new Date().toISOString()
      });
      
      await supabase
        .from('calls')
        .update({
          processing_status: 'error',
          error_message: `×©×’×™××ª × ×™×ª×•×—: ${analysisError.message}`
        })
        .eq('id', call_id);

      return NextResponse.json(
        { error: '×”× ×™×ª×•×— × ×›×©×œ', details: analysisError.message },
        { status: 500 }
      );
    }

    const totalTime = Math.round((Date.now() - startTime) / 1000);
    console.log(`âœ… Process completed successfully in ${totalTime} seconds`);
    
    return NextResponse.json({
      success: true,
      call_id,
      message: '× ×™×ª×•×— ×”×©×™×—×” ×”×•×©×œ× ×‘×”×¦×œ×—×”',
      execution_time_seconds: totalTime
    });

  } catch (error: any) {
    console.error('âŒ General error:', error);
    
    return NextResponse.json(
      { error: error.message },
      { status: 500 }
    );
  }
} 