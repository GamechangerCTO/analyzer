import { createClient } from '@/lib/supabase/server'
import { NextResponse } from 'next/server'
import OpenAI from 'openai'

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
})

// ×¤×•× ×§×¦×™×” ×œ× ×™×§×•×™ ×ª×©×•×‘×•×ª JSON ×-OpenAI
function cleanOpenAIResponse(content: string): string {
  if (!content) return '{}'
  
  let cleaned = content.replace(/```(?:json|JSON)?\s*/g, '').replace(/```\s*$/g, '')
  cleaned = cleaned.replace(/^`+|`+$/g, '').trim()
  
  const jsonStart = cleaned.indexOf('{')
  if (jsonStart !== -1) {
    cleaned = cleaned.substring(jsonStart)
  }
  
  // ××œ×’×•×¨×™×ª× ××™×–×•×Ÿ ×¡×•×’×¨×™×™×
  let braceCount = 0
  let lastValidEnd = -1
  
  for (let i = 0; i < cleaned.length; i++) {
    const char = cleaned[i]
    if (char === '{') braceCount++
    else if (char === '}') {
      braceCount--
      if (braceCount === 0) {
        lastValidEnd = i
        break
      }
    }
  }
  
  if (lastValidEnd !== -1) {
    cleaned = cleaned.substring(0, lastValidEnd + 1)
  }
  
  return cleaned
}

export async function POST(request: Request) {
  const startTime = Date.now()
  
  try {
    const formData = await request.formData()
    const audioFile = formData.get('audio') as File | null
    const simulationId = formData.get('simulationId') as string
    const textInput = formData.get('textInput') as string | null // ××•×¤×¦×™×•× ×œ×™ - ×× ×¨×•×¦×™× ×œ×”×©×ª××© ×‘×˜×§×¡×˜ ×‘××§×•× ××•×“×™×•
    
    if (!simulationId) {
      return NextResponse.json({ error: '×—×¡×¨ ××–×”×” ×¡×™××•×œ×¦×™×”' }, { status: 400 })
    }
    
    if (!audioFile && !textInput) {
      return NextResponse.json({ error: '× ×“×¨×© ×§×œ×˜ ××•×“×™×• ××• ×˜×§×¡×˜' }, { status: 400 })
    }
    
    const supabase = createClient()
    
    // ×‘×“×™×§×ª ××™××•×ª
    const { data: { user }, error: authError } = await supabase.auth.getUser()
    if (authError || !user) {
      return NextResponse.json({ error: '×œ× ×××•××ª' }, { status: 401 })
    }
    
    // ×©×œ×™×¤×ª ×”×¡×™××•×œ×¦×™×” ×¢× ×”×¤×¨×¡×•× ×”
    const { data: simulation, error: simError } = await supabase
      .from('simulations')
      .select(`
        *,
        customer_personas_hebrew (*)
      `)
      .eq('id', simulationId)
      .single()
    
    if (simError || !simulation) {
      console.error('Error fetching simulation:', simError)
      return NextResponse.json({ error: '×¡×™××•×œ×¦×™×” ×œ× × ××¦××”' }, { status: 404 })
    }
    
    // ×‘×“×™×§×ª ×”×¨×©××”
    if (simulation.agent_id !== user.id) {
      return NextResponse.json({ error: '××™×Ÿ ×”×¨×©××”' }, { status: 403 })
    }
    
    // ×©×œ×™×¤×ª ×©××œ×•×Ÿ ×—×‘×¨×”
    const { data: questionnaire } = await supabase
      .from('company_questionnaires')
      .select('*')
      .eq('company_id', simulation.company_id)
      .single()
    
    let userTranscript = textInput || ''
    let toneAnalysis = null
    
    // ×©×œ×‘ 1: ×ª××œ×•×œ ×”××•×“×™×• (×× ×™×©)
    if (audioFile && !textInput) {
      console.log('ğŸ“ ××ª××œ×œ ××•×“×™×•...')
      const transcriptionStart = Date.now()
      
      try {
        const transcription = await openai.audio.transcriptions.create({
          file: audioFile,
          model: 'gpt-4o-mini-transcribe',
          language: 'he',
          response_format: 'verbose_json'
        })
        
        userTranscript = transcription.text
        console.log(`âœ… ×ª××œ×•×œ ×”×•×©×œ× ×‘-${Date.now() - transcriptionStart}ms: "${userTranscript.substring(0, 100)}..."`)
      } catch (transcriptionError) {
        console.error('âŒ ×©×’×™××” ×‘×ª××œ×•×œ:', transcriptionError)
        return NextResponse.json({ 
          error: '×©×’×™××” ×‘×ª××œ×•×œ ×”××•×“×™×•',
          details: transcriptionError instanceof Error ? transcriptionError.message : 'Unknown'
        }, { status: 500 })
      }
    }
    
    if (!userTranscript || userTranscript.trim() === '') {
      return NextResponse.json({ error: '×œ× ×–×•×”×” ×˜×§×¡×˜ ×‘×§×œ×˜' }, { status: 400 })
    }
    
    // ×©×œ×‘ 2: ×‘× ×™×™×ª ×”-system prompt
    const persona = simulation.customer_personas_hebrew
    const systemPrompt = buildCustomerPersonaPrompt(persona, questionnaire, simulation.selected_topics || [])
    
    // ×©×œ×‘ 3: ×‘× ×™×™×ª ×”×™×¡×˜×•×¨×™×™×ª ×”×©×™×—×”
    const conversationHistory = simulation.conversation_history || []
    
    // ×”×•×¡×¤×ª ×”×”×•×“×¢×” ×©×œ ×”××©×ª××© ×œ×”×™×¡×˜×•×¨×™×”
    conversationHistory.push({
      role: 'user',
      content: userTranscript,
      timestamp: new Date().toISOString()
    })
    
    // ×©×œ×‘ 4: ×§×¨×™××” ×œ-GPT-5-nano ×¢× Responses API
    console.log('ğŸ§  ×©×•×œ×— ×œ-GPT-5-nano...')
    const responseStart = Date.now()
    
    let aiResponse: string
    let newResponseId: string | null = null
    
    try {
      // ×‘× ×™×™×ª ×”-input ×¢× ×›×œ ×”×”×™×¡×˜×•×¨×™×”
      const messages = [
        { role: 'system' as const, content: systemPrompt },
        ...conversationHistory.map((msg: any) => ({
          role: msg.role as 'user' | 'assistant',
          content: msg.content
        }))
      ]
      
      // ×©×™××•×© ×‘-Responses API ×¢× previous_response_id ×œ×©××™×¨×ª context
      const responseParams: any = {
        model: 'gpt-5-nano-2025-08-07',
        input: messages,
        reasoning: { effort: 'low' },
        text: { verbosity: 'medium' }
      }
      
      // ×× ×™×© response ×§×•×“× - ××©×ª××©×™× ×‘×• ×œ×©××™×¨×ª context
      if (simulation.last_response_id) {
        responseParams.previous_response_id = simulation.last_response_id
        // ×›×©×™×© previous_response_id, ×©×•×œ×—×™× ×¨×§ ××ª ×”×”×•×“×¢×” ×”×—×“×©×”
        responseParams.input = userTranscript
      }
      
      const response = await (openai as any).responses.create(responseParams)
      
      aiResponse = response.output_text || response.output?.[0]?.content || '××¦×˜×¢×¨, ×œ× ×”×¦×œ×—×ª×™ ×œ×”×‘×™×Ÿ. ××¤×©×¨ ×œ×—×–×•×¨ ×¢×œ ×–×”?'
      newResponseId = response.id
      
      console.log(`âœ… ×ª×©×•×‘×” ×”×ª×§×‘×œ×” ×‘-${Date.now() - responseStart}ms`)
    } catch (apiError: any) {
      console.error('âŒ ×©×’×™××” ×‘×§×¨×™××” ×œ-GPT-5-nano:', apiError)
      
      // Fallback ×œ-Chat Completions API ×× Responses API ×œ× ×¢×•×‘×“
      console.log('âš ï¸ ××©×ª××© ×‘-fallback ×œ-Chat Completions...')
      
      const messages = [
        { role: 'system' as const, content: systemPrompt },
        ...conversationHistory.map((msg: any) => ({
          role: msg.role as 'user' | 'assistant',
          content: msg.content
        }))
      ]
      
      const fallbackResponse = await openai.chat.completions.create({
        model: 'gpt-4o-mini',
        messages: messages,
        temperature: 0.7,
        max_tokens: 300
      })
      
      aiResponse = fallbackResponse.choices[0]?.message?.content || '××¦×˜×¢×¨, ×œ× ×”×¦×œ×—×ª×™ ×œ×”×‘×™×Ÿ.'
    }
    
    // ×”×•×¡×¤×ª ×ª×©×•×‘×ª ×”-AI ×œ×”×™×¡×˜×•×¨×™×”
    conversationHistory.push({
      role: 'assistant',
      content: aiResponse,
      timestamp: new Date().toISOString()
    })
    
    // ×©×œ×‘ 5: ×”××¨×” ×œ-TTS
    console.log('ğŸ”Š ×××™×¨ ×œ-TTS...')
    const ttsStart = Date.now()
    
    let audioBase64 = null
    
    try {
      // ×‘×—×™×¨×ª ×§×•×œ ×œ×¤×™ ××’×“×¨ ×”×¤×¨×¡×•× ×”
      // ×§×•×œ×•×ª × ×ª××›×™×: alloy, ash, ballad, coral, echo, sage, shimmer, verse, marin, cedar
      const voice = persona?.voice_characteristics?.gender === 'female' ? 'coral' : 'echo'
      
      const ttsResponse = await openai.audio.speech.create({
        model: 'tts-1',
        voice: voice,
        input: aiResponse,
        response_format: 'mp3',
        speed: 1.0
      })
      
      const audioBuffer = await ttsResponse.arrayBuffer()
      audioBase64 = Buffer.from(audioBuffer).toString('base64')
      
      console.log(`âœ… TTS ×”×•×©×œ× ×‘-${Date.now() - ttsStart}ms`)
    } catch (ttsError) {
      console.error('âš ï¸ ×©×’×™××” ×‘-TTS, ×××©×™×š ×œ×œ× ××•×“×™×•:', ttsError)
    }
    
    // ×©×œ×‘ 6: ×¢×“×›×•×Ÿ ×”×¡×™××•×œ×¦×™×” ×‘-DB
    const { error: updateError } = await supabase
      .from('simulations')
      .update({
        conversation_history: conversationHistory,
        last_response_id: newResponseId,
        current_turn: (simulation.current_turn || 0) + 1,
        status: 'in_progress',
        started_at: simulation.started_at || new Date().toISOString()
      })
      .eq('id', simulationId)
    
    if (updateError) {
      console.error('âš ï¸ ×©×’×™××” ×‘×¢×“×›×•×Ÿ ×”×¡×™××•×œ×¦×™×”:', updateError)
    }
    
    const totalTime = Date.now() - startTime
    console.log(`âœ… ×ª×•×¨ ×©×™×—×” ×”×•×©×œ× ×‘-${totalTime}ms`)
    
    return NextResponse.json({
      success: true,
      userTranscript,
      aiResponse,
      audioBase64,
      audioFormat: 'mp3',
      turnNumber: (simulation.current_turn || 0) + 1,
      toneAnalysis,
      timing: {
        total: totalTime
      }
    })
    
  } catch (error) {
    console.error('âŒ ×©×’×™××” ×›×œ×œ×™×ª ×‘×ª×•×¨ ×©×™×—×”:', error)
    return NextResponse.json({ 
      error: '×©×’×™××” ×‘×¢×™×‘×•×“ ×ª×•×¨ ×”×©×™×—×”',
      details: error instanceof Error ? error.message : 'Unknown error'
    }, { status: 500 })
  }
}

// ×‘× ×™×™×ª prompt ×œ×¤×¨×¡×•× ×ª ×œ×§×•×—
function buildCustomerPersonaPrompt(
  persona: any, 
  questionnaire: any,
  selectedTopics: string[]
): string {
  const companyContext = questionnaire ? `
×”×§×©×¨ ×¢×¡×§×™:
- ×ª×—×•×: ${questionnaire.industry || '×œ× ×¦×•×™×Ÿ'}
- ××•×¦×¨/×©×™×¨×•×ª: ${questionnaire.product_service || '×œ× ×¦×•×™×Ÿ'}
- ×§×”×œ ×™×¢×“: ${questionnaire.target_audience || '×œ× ×¦×•×™×Ÿ'}
- ×‘×™×“×•×œ: ${questionnaire.key_differentiator || '×œ× ×¦×•×™×Ÿ'}
` : ''

  const topicsInstruction = selectedTopics.length > 0 ? `
ğŸ¯ × ×•×©××™× ×œ×‘×“×™×§×” ×‘×©×™×—×” ×–×•:
${selectedTopics.map(t => `- ${t.replace(/_/g, ' ')}`).join('\n')}

×”×ª××§×“ ×‘××ª×’×¨ ×”× ×¦×™×’ ×‘× ×•×©××™× ××œ×” ×‘××™×•×—×“!
` : ''

  const personaName = persona?.persona_name || '×œ×§×•×— ×›×œ×œ×™'
  const personalityType = persona?.personality_type || '×¡×˜× ×“×¨×˜×™'
  const communicationStyle = persona?.communication_style || '×™×©×™×¨'
  const backgroundStory = persona?.background_story || ''
  const currentSituation = persona?.current_situation || ''
  const painPoints = persona?.pain_points || []
  const commonObjections = persona?.common_objections || []
  
  return `××ª×” ${personaName}, ×œ×§×•×— ×¤×•×˜× ×¦×™××œ×™ ×‘×©×™×—×ª ××›×™×¨×•×ª/×©×™×¨×•×ª.

ğŸ­ ×”×“××•×ª ×©×œ×š:
- ×¡×•×’ ××™×©×™×•×ª: ${personalityType}
- ×¡×’× ×•×Ÿ ×ª×§×©×•×¨×ª: ${communicationStyle}
- ×¨×§×¢: ${backgroundStory}
- ××¦×‘ × ×•×›×—×™: ${currentSituation}

${companyContext}

${topicsInstruction}

ğŸ˜¤ × ×§×•×“×•×ª ×›××‘:
${painPoints.map((p: string) => `- ${p}`).join('\n') || '- ××—×¤×© ×¤×ª×¨×•×Ÿ ××ª××™×'}

ğŸ›¡ï¸ ×”×ª× ×’×“×•×™×•×ª × ×¤×•×¦×•×ª ×©×œ×š:
${commonObjections.map((o: string) => `- ${o}`).join('\n') || '- ××—×™×¨, ×–××Ÿ, ×¦×•×¨×š ×‘×”×ª×™×™×¢×¦×•×ª'}

ğŸ“ ×›×œ×œ×™× ×—×©×•×‘×™×:
1. ××ª×” ×”×œ×§×•×— - ×œ× ×”××•×›×¨!
2. ×“×‘×¨ ×‘×¢×‘×¨×™×ª ×˜×‘×¢×™×ª ×•×§×•×œ×—×ª
3. ×ª×’×™×‘ ×›××• ×œ×§×•×— ×××™×ª×™ - ×œ×¤×¢××™× ××”×¡×¡, ×œ×¤×¢××™× ××ª×¢× ×™×™×Ÿ
4. ×”×¢×œ×” ×”×ª× ×’×“×•×™×•×ª ×‘××•×¤×Ÿ ×˜×‘×¢×™
5. ×ª×©×•×‘×•×ª ×§×¦×¨×•×ª (2-3 ××©×¤×˜×™× ××§×¡×™××•×)
6. ××œ ×ª×”×™×” ×§×œ ××“×™ - ×–×• ×¡×™××•×œ×¦×™×™×ª ××™××•×Ÿ
7. ×× ×”× ×¦×™×’ ×¢×•×©×” ×¢×‘×•×“×” ×˜×•×‘×” - ××¤×©×¨ ×œ×”×ª×§×“× ×œ×¢×‘×¨ ×¡×’×™×¨×”
8. ×× ×”× ×¦×™×’ ×œ× ××ª××•×“×“ ×˜×•×‘ - ×—×–×§ ××ª ×”×”×ª× ×’×“×•×™×•×ª

×”×ª×—×œ ××ª ×”×©×™×—×” ×›××™×œ×• ××ª×” ×œ×§×•×— ×©×¤×•× ×” ××• ×©×¤× ×• ××œ×™×•.`
}

// GET - ×©×œ×™×¤×ª ×”×™×¡×˜×•×¨×™×™×ª ×©×™×—×”
export async function GET(request: Request) {
  try {
    const { searchParams } = new URL(request.url)
    const simulationId = searchParams.get('simulationId')
    
    if (!simulationId) {
      return NextResponse.json({ error: '×—×¡×¨ ××–×”×” ×¡×™××•×œ×¦×™×”' }, { status: 400 })
    }
    
    const supabase = createClient()
    
    const { data: { user }, error: authError } = await supabase.auth.getUser()
    if (authError || !user) {
      return NextResponse.json({ error: '×œ× ×××•××ª' }, { status: 401 })
    }
    
    const { data: simulation, error } = await supabase
      .from('simulations')
      .select('conversation_history, current_turn, status')
      .eq('id', simulationId)
      .eq('agent_id', user.id)
      .single()
    
    if (error || !simulation) {
      return NextResponse.json({ error: '×¡×™××•×œ×¦×™×” ×œ× × ××¦××”' }, { status: 404 })
    }
    
    return NextResponse.json({
      conversationHistory: simulation.conversation_history || [],
      currentTurn: simulation.current_turn || 0,
      status: simulation.status
    })
    
  } catch (error) {
    console.error('Error fetching conversation:', error)
    return NextResponse.json({ error: '×©×’×™××” ×‘×©×œ×™×¤×ª ×”×©×™×—×”' }, { status: 500 })
  }
}

