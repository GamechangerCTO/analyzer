'use client'

import { useState, useEffect, useRef } from 'react'
import { useRouter } from 'next/navigation'
import { createCustomizedSimulationPrompt, getSimulationPromptFromDB, type SimulationPromptParams } from '@/lib/simulation-prompts-db'

interface RealtimeSimulationProps {
  simulation: any
  customerPersona?: any
  user: any
  company: any
}

type SimulationStatus = 'preparing' | 'connecting' | 'ready' | 'active' | 'ending' | 'completed' | 'error'

export default function RealtimeSimulation({ simulation, customerPersona, user, company }: RealtimeSimulationProps) {
  const router = useRouter()
  const [status, setStatus] = useState<SimulationStatus>('preparing')
  const [isAudioEnabled, setIsAudioEnabled] = useState(false)
  const [transcript, setTranscript] = useState<string[]>([])
  const [audioContext, setAudioContext] = useState<AudioContext | null>(null)
  const [mediaStream, setMediaStream] = useState<MediaStream | null>(null)
  const [peerConnection, setPeerConnection] = useState<RTCPeerConnection | null>(null)
  const [dataChannel, setDataChannel] = useState<RTCDataChannel | null>(null)
  const [sessionStarted, setSessionStarted] = useState(false)
  const [currentMessage, setCurrentMessage] = useState('')
  const [simulationMetrics, setSimulationMetrics] = useState({
    startTime: null as Date | null,
    responseTime: 0,
    interruptionsCount: 0,
    currentObjection: null as string | null
  })

  const audioElementRef = useRef<HTMLAudioElement | null>(null)
  const ephemeralKeyRef = useRef<string | null>(null)

  // ×”×’×“×¨×ª ×¤×¨×¡×•× ×ª ×”×œ×§×•×— ×œ-AI (×§×‘×œ×ª ×”×¤×¨×¡×•× ×” ××”×¤×¨××˜×¨ ××• ××”×¡×™××•×œ×¦×™×”)
  const persona = customerPersona || simulation.customer_personas_hebrew?.[0]
  
  // ×§×‘×™×¢×ª ×§×•×œ ×‘×”×ª×× ×œ×¤×¨×¡×•× ×”
  const getVoiceForPersona = () => {
    // ×‘×“×™×§×” ×× ×™×© ×”×’×“×¨×” ×¡×¤×¦×™×¤×™×ª ×‘×¤×¨×¡×•× ×”
    if (persona?.voice_characteristics?.gender) {
      if (persona.voice_characteristics.gender === 'male' || persona.voice_characteristics.gender === '×–×›×¨') {
        return 'onyx' // ×§×•×œ ×’×‘×¨×™ - ×™×•×ª×¨ ×˜×‘×¢×™ ×‘×¢×‘×¨×™×ª
      } else {
        return 'coral' // ×§×•×œ × ×©×™ - ×™×•×ª×¨ ×˜×‘×¢×™ ×‘×¢×‘×¨×™×ª
      }
    }
    
    // ×‘×“×™×§×” ×œ×¤×™ ×©× ×”×¤×¨×¡×•× ×”
    const personaName = persona?.persona_name || ''
    const maleNames = ['×“× ×™', '×××™×¨', '×™×•×¡×™', '×“×•×“', '××™×›××œ', '×¨×•×Ÿ', '××‘×™', '×’×™×œ', '×™×•× ×ª×Ÿ', '××™×ª××¨', '×™×¢×§×‘', '××©×”', '××‘×¨×”×', '×™×¦×—×§', '××”×¨×•×Ÿ', '×©××•××œ', '×‘× ×™××™×Ÿ', '××œ×™×¢×–×¨', '×™×”×•×©×¢', '×—×™×™×']
    const femaleNames = ['×“× ×”', '××™×›×œ', '×©×¨×”', '×¨×•×ª×™', '×œ×™××ª', '× ×•×¢×”', '×ª××¨', '×¢× ×ª', '×¨×•× ×™×ª', '×™×¢×œ']
    
    if (maleNames.some(name => personaName.includes(name))) {
      return 'onyx' // ×§×•×œ ×’×‘×¨×™ - ×™×•×ª×¨ ×˜×‘×¢×™ ×‘×¢×‘×¨×™×ª
    } else if (femaleNames.some(name => personaName.includes(name))) {
      return 'coral' // ×§×•×œ × ×©×™ - ×™×•×ª×¨ ×˜×‘×¢×™ ×‘×¢×‘×¨×™×ª
    }
    
    // ×‘×¨×™×¨×ª ××—×“×œ - × ×§×‘×” (×›×™ ×¨×•×‘ ×¤×¨×¡×•× ×•×ª ×”×œ×§×•×—×•×ª × ×©×™× ×‘× ×™×¡×™×•×Ÿ ×©×œ×™)
    return 'coral'
  }

  const [aiInstructions, setAiInstructions] = useState('')

  // ×˜×¢×™× ×ª ×¤×¨×•××¤×˜ ××”××¡×“ ×”× ×ª×•× ×™×
  useEffect(() => {
    const loadPromptFromDB = async () => {
      if (!persona) return
      
      try {
        // ×§×‘×™×¢×ª ×¡×•×’ ×”×¡×™××•×œ×¦×™×” ×œ×¤×™ ×”× ×ª×•× ×™×
        const callType = simulation.simulation_type || 'inbound'
        
        // ×—×™×œ×•×¥ ×¤×¨××˜×¨×™× ×—×œ×©×™× ××”×¡×™××•×œ×¦×™×” (×× ×§×™×™××™×)
        const focusedParameters = simulation.focused_parameters || []
        const agentWeaknesses = focusedParameters.map((param: any) => ({
          name: param.hebrewName || param.name,
          score: param.score,
          category: param.category
        }))
        
        // âœ… ×—×™×œ×•×¥ × ×•×©××™× × ×‘×—×¨×™× ××”×¡×™××•×œ×¦×™×”
        const selectedTopics = simulation.selected_topics || []
        
        // ×™×¦×™×¨×ª ×¤×¨××˜×¨×™× ×œ×¤×¨×•××¤×˜
        const promptParams: SimulationPromptParams = {
          personaName: persona.persona_name || '×œ×§×•×—',
          personalityType: persona.personality_type || '×™×“×™×“×•×ª×™',
          communicationStyle: persona.communication_style || '×™×©×™×¨',
          backgroundStory: persona.background_story || '×œ×§×•×— ×¤×•×˜× ×¦×™××œ×™',
          currentSituation: persona.current_situation || '××¢×•× ×™×™×Ÿ ×œ××™×“×¢',
          commonObjections: persona.common_objections || ['×”××—×™×¨ × ×©××¢ ×™×§×¨', '×× ×™ ×¦×¨×™×š ×œ×—×©×•×‘'],
          targetsWeaknesses: persona.targets_weaknesses || [],
          difficultyLevel: simulation.difficulty_level || 'medium',
          companyName: company?.name,
          industry: company?.company_questionnaires?.[0]?.industry,
          productService: company?.company_questionnaires?.[0]?.product_service,
          callType: callType as any,
          specificScenario: simulation.scenario_description,
          agentWeaknesses: agentWeaknesses,
          selectedTopics: selectedTopics // âœ… ×”× ×•×©××™× ×©× ×‘×—×¨×•
        }
        
        // ×™×¦×™×¨×ª ×¤×¨×•××¤×˜ ××•×ª×× ××”××¡×“ ×”× ×ª×•× ×™×
        const customPrompt = await createCustomizedSimulationPrompt(promptParams)
        setAiInstructions(customPrompt)
        
        console.log('âœ… ×¤×¨×•××¤×˜ ×¡×™××•×œ×¦×™×” × ×˜×¢×Ÿ ××”××¡×“ ×”× ×ª×•× ×™×', {
          weaknessesCount: agentWeaknesses.length,
          weaknesses: agentWeaknesses
        })
      } catch (error) {
        console.error('âŒ ×©×’×™××” ×‘×˜×¢×™× ×ª ×¤×¨×•××¤×˜ ××”××¡×“, ××©×ª××© ×‘×¤×¨×•××¤×˜ ×‘×¨×™×¨×ª ××—×“×œ:', error)
        setAiInstructions(createFallbackInstructions())
      }
    }
    
    loadPromptFromDB()
  }, [persona, simulation, company])

  const createFallbackInstructions = () => {
    const isGenderMale = getVoiceForPersona() === 'onyx'
    const genderText = isGenderMale ? '×œ×§×•×—' : '×œ×§×•×—×”'
    
    // ×—×™×œ×•×¥ ×¤×¨××˜×¨×™× ×—×œ×©×™×
    const focusedParameters = simulation.focused_parameters || []
    const weaknessSection = focusedParameters.length > 0 ? `

## ğŸ¯ ××™×§×•×“ ××™×•×—×“ - ×ª×—×•××™× ×œ×©×™×¤×•×¨:
×”× ×¦×™×’ ×¦×¨×™×š ×œ×ª×¨×’×œ ××ª ×”×ª×—×•××™× ×”×‘××™× ×©×‘×”× ×”×•× ×—×œ×©:

${focusedParameters.map((p: any) => `- **${p.hebrewName || p.name}** (×¦×™×•×Ÿ × ×•×›×—×™: ${p.score}/10)
  ×ª××ª×’×¨ ××•×ª×• ×‘××™×•×—×“ ×‘×ª×—×•× ×”×–×”!`).join('\n')}

**××¡×˜×¨×˜×’×™×™×ª ×”××ª×’×¨:**
- ×× ×”× ×¦×™×’ ×œ× ××˜×¤×œ ×˜×•×‘ ×‘×”×ª× ×’×“×•×ª - ×ª×Ÿ ×œ×• ×¢×•×“ ×”×ª× ×’×“×•×ª ×§×©×” ×™×•×ª×¨
- ×× ×”× ×¦×™×’ ×œ× ××‘×¦×¢ ×‘×™×¨×•×¨ - ×”×™×” ××¢×•×¨×¤×œ ×•×ª××ª×™×Ÿ ×©×”×•× ×™×©××œ
- ×× ×”× ×¦×™×’ ×œ× ×¡×•×’×¨ - ×ª×™×©××¨ ××”×¡×¡ ×’× ××—×¨×™ ×”×¦×¢×” ×˜×•×‘×”
- ×–×›×•×¨: ××ª×” ×›××Ÿ ×œ×××Ÿ, ×œ× ×œ× ×¦×—! ×ª×Ÿ ×¨××–×™× ×× ×”× ×¦×™×’ ×ª×§×•×¢

ğŸ¯ ×”××˜×¨×”: ×œ×¨××•×ª ×©×™×¤×•×¨ ×‘-${focusedParameters.length} ×”×ª×—×•××™× ×”××œ×”!
` : ''
    
    return `ğŸ¯ **××ª×” ${persona?.persona_name || '×”×œ×§×•×—'}** - ${genderText} ×‘××¢×¨×›×ª ××™××•×Ÿ

## âš ï¸ ×”×‘×”×¨×” ×§×¨×™×˜×™×ª - ×§×¨× ×‘×¢×™×•×Ÿ!
- **××ª×” = ×”×œ×§×•×—** ×©××ª×§×©×¨ ××• ××§×‘×œ ×©×™×—×”
- **×”××©×ª××© ×©××•×œ×š = ××™×© ×”××›×™×¨×•×ª/×©×™×¨×•×ª** ×©×× ×¡×” ×œ××›×•×¨ ×œ×š
- **××ª×” ×œ× ××™×© ××›×™×¨×•×ª!** ××œ ×ª×©××œ "××™×š ××•×›×œ ×œ×¢×–×•×¨ ×œ×š"

## ğŸ­ ×ª×¤×§×™×“×š ×›×œ×§×•×—:
- ${persona?.background_story || '××ª×” ×œ×§×•×— ×©××—×¤×© ×¤×ª×¨×•×Ÿ'}
- ${persona?.current_situation || '××¢×•× ×™×™×Ÿ ×œ×©××•×¢ ×¢×œ ×”××•×¦×¨/×©×™×¨×•×ª'}

## ğŸ“‹ ××™×š ×œ×”×ª× ×”×’ ×›×œ×§×•×—:
- ×¤×ª×— ×‘×”×¦×’×” ×¢×¦××™×ª: "×©×œ×•×, ×× ×™ ${persona?.persona_name || '××ª×§×©×¨'}, ×¨××™×ª×™ ××ª ×”×¤×¨×¡×•× ×©×œ×›×..."
- ×©××œ ×©××œ×•×ª ×¢×œ ×”××•×¦×¨/×©×™×¨×•×ª
- ×”×¢×œ×” ×”×ª× ×’×“×•×™×•×ª ×‘××•×¤×Ÿ ×˜×‘×¢×™
- ×”×™×” ×§×¦×ª ××”×¡×¡ - ××œ ×ª×¡×›×™× ××™×“

## ğŸš« ××” ×œ× ×œ×¢×©×•×ª:
- ×œ× ×œ×©××•×œ "××™×š ××•×›×œ ×œ×¢×–×•×¨ ×œ×š" - ×–×” ××©×¤×˜ ×©×œ × ×¦×™×’!
- ×œ× ×œ×”×¦×™×¢ ×¤×ª×¨×•× ×•×ª - ××ª×” ×”×œ×§×•×—!
- ×œ× ×œ× ×”×œ ××ª ×”×©×™×—×” - ×ª×Ÿ ×œ××™×© ×”××›×™×¨×•×ª ×œ×”×•×‘×™×œ

## ×”×ª× ×’×“×•×™×•×ª ×©×œ×š:
${persona?.common_objections?.map((obj: string) => `- ${obj}`).join('\n') || '- ×× ×™ ×¦×¨×™×š ×œ×—×©×•×‘ ×¢×œ ×–×”\n- × ×©××¢ ×™×§×¨\n- ×™×© ×œ×™ ×¡×¤×§ ××—×¨'}
${weaknessSection}

ğŸ—£ï¸ ×“×‘×¨ ×‘×¢×‘×¨×™×ª ×˜×‘×¢×™×ª. ×–×›×•×¨: ××ª×” **×”×œ×§×•×—**! ğŸ¯
`
  }

  // ×§×‘×œ×ª ephemeral token ××”×©×¨×ª
  const getEphemeralToken = async () => {
    try {
      setStatus('connecting')
      const response = await fetch('/api/simulations/ephemeral-token', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ 
          simulationId: simulation.id,
          instructions: createAIInstructions(),
          voice: getVoiceForPersona()
        })
      })

      if (!response.ok) {
        throw new Error('Failed to get ephemeral token')
      }

      const data = await response.json()
      ephemeralKeyRef.current = data.client_secret?.value
      
      if (!ephemeralKeyRef.current) {
        throw new Error('No ephemeral token received')
      }

      return ephemeralKeyRef.current
    } catch (error) {
      console.error('Error getting ephemeral token:', error)
      setStatus('error')
      throw error
    }
  }

  // ×”×’×“×¨×ª WebRTC connection
  const initializeWebRTC = async () => {
    try {
      if (!ephemeralKeyRef.current) {
        await getEphemeralToken()
      }

      // ×™×¦×™×¨×ª peer connection
      const pc = new RTCPeerConnection({
        iceServers: [{ urls: 'stun:stun.l.google.com:19302' }]
      })

      // ×”×’×“×¨×ª audio element ×œ×§×‘×œ×ª ××•×“×™×• ××”-AI
      if (!audioElementRef.current) {
        const audioEl = document.createElement('audio')
        audioEl.autoplay = true
        audioEl.setAttribute('playsinline', 'true')
        audioElementRef.current = audioEl
      }

      pc.ontrack = (event) => {
        if (audioElementRef.current) {
          audioElementRef.current.srcObject = event.streams[0]
        }
      }

      // ×§×‘×œ×ª microphone ××”××©×ª××©
      const mediaStream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 16000
        } 
      })
      
      setMediaStream(mediaStream)
      pc.addTrack(mediaStream.getTracks()[0])

      // ×™×¦×™×¨×ª data channel ×œ×¢×“×›×•× ×™×
      const dc = pc.createDataChannel('oai-events')
      setDataChannel(dc)

      dc.onopen = () => {
        console.log('ğŸ¯ Data channel × ×¤×ª×— - ××•×›×Ÿ ×œ×ª×§×©×•×¨×ª')
        setStatus('ready')
      }

      dc.onmessage = (event) => {
        try {
          const serverEvent = JSON.parse(event.data)
          handleServerEvent(serverEvent)
        } catch (error) {
          console.error('Error parsing server event:', error)
        }
      }

      // ×™×¦×™×¨×ª SDP offer
      const offer = await pc.createOffer()
      await pc.setLocalDescription(offer)

      // ×©×œ×™×—×” ×œOpenAI Realtime API
      const baseUrl = "https://api.openai.com/v1/realtime"
      const model = "gpt-realtime-mini-2025-10-06"
      
      console.log('ğŸ”‘ Ephemeral token:', ephemeralKeyRef.current?.substring(0, 20) + '...')
      console.log('ğŸ“¡ Sending SDP offer to:', `${baseUrl}?model=${model}`)
      
      const sdpResponse = await fetch(`${baseUrl}?model=${model}`, {
        method: "POST",
        body: offer.sdp,
        headers: {
          Authorization: `Bearer ${ephemeralKeyRef.current}`,
          "Content-Type": "application/sdp",
          "OpenAI-Beta": "realtime=v1"
        },
      })

      if (!sdpResponse.ok) {
        const errorText = await sdpResponse.text()
        console.error('ğŸ”´ SDP request failed:', {
          status: sdpResponse.status,
          statusText: sdpResponse.statusText,
          error: errorText,
          headers: Object.fromEntries(sdpResponse.headers.entries())
        })
        throw new Error(`SDP request failed: ${sdpResponse.status} - ${errorText}`)
      }

      const answer = {
        type: "answer" as RTCSdpType,
        sdp: await sdpResponse.text(),
      }
      
      await pc.setRemoteDescription(answer)
      
      setPeerConnection(pc)
      console.log('âœ… WebRTC connection ×”×•×§× ×‘×”×¦×œ×—×”')

    } catch (error) {
      console.error('âŒ ×©×’×™××” ×‘×”×§××ª WebRTC:', error)
      setStatus('error')
      throw error
    }
  }

  // ×˜×™×¤×•×œ ×‘××™×¨×•×¢×™ ×”×©×¨×ª
  const handleServerEvent = (event: any) => {
    console.log('ğŸ“¨ Server event:', event.type, event)

    switch (event.type) {
      case 'session.created':
        console.log('ğŸ‰ ×¡×©×Ÿ × ×•×¦×¨ ×‘×”×¦×œ×—×”')
        console.log('ğŸ“Š dataChannel ×–××™×Ÿ:', !!dataChannel)
        console.log('ğŸ“Š sessionStarted:', sessionStarted)
        startSimulation()
        break

      case 'response.audio_transcript.delta':
        if (event.delta) {
          setCurrentMessage(prev => prev + event.delta)
        }
        break

                case 'response.audio_transcript.done':
        if (event.transcript) {
          setTranscript(prev => [...prev, `ğŸ¤– ${persona?.persona_name || '×œ×§×•×—'}: ${event.transcript}`])
          setCurrentMessage('')
        }
        break

      case 'input_audio_buffer.speech_started':
        console.log('ğŸ¤ ×”× ×¦×™×’ ×”×ª×—×™×œ ×œ×“×‘×¨')
        setSimulationMetrics(prev => ({
          ...prev,
          responseTime: Date.now()
        }))
        break

      case 'input_audio_buffer.speech_stopped':
        console.log('ğŸ”‡ ×”× ×¦×™×’ ×”×¤×¡×™×§ ×œ×“×‘×¨')
        break

      case 'conversation.item.input_audio_transcription.completed':
        if (event.transcript) {
          setTranscript(prev => [...prev, `ğŸ‘¤ ××ª×”: ${event.transcript}`])
        }
        break

      case 'error':
        console.error('âŒ ×©×’×™××” ××”×©×¨×ª:', event)
        setStatus('error')
        break

      default:
        // ××™×¨×•×¢×™× × ×•×¡×¤×™×...
        break
    }
  }

  // ×”×ª×—×œ×ª ×”×¡×™××•×œ×¦×™×”
  const startSimulation = () => {
    console.log('ğŸš€ ××ª×—×™×œ ×¡×™××•×œ×¦×™×”, dataChannel:', !!dataChannel)
    if (!dataChannel) {
      console.error('âŒ ××™×Ÿ dataChannel - ×œ× ×™×›×•×œ ×œ×”×ª×—×™×œ ×¡×™××•×œ×¦×™×”')
      return
    }

    console.log('âœ… ××¢×“×›×Ÿ ×¡×˜×˜×•×¡ ×œ-active')
    setStatus('active')
    setSessionStarted(true)
    setSimulationMetrics(prev => ({
      ...prev,
      startTime: new Date()
    }))

    // ×”×’×“×¨×ª session ×¢× ×”×”×•×¨××•×ª
    const sessionUpdate = {
      type: "session.update",
      session: {
        type: "realtime",
        model: "gpt-realtime-mini-2025-10-06",
        modalities: ["text", "audio"],
        instructions: createAIInstructions(),
        voice: getVoiceForPersona(),
        input_audio_format: "pcm16",
        output_audio_format: "pcm16",
        input_audio_transcription: {
          model: "gpt-4o-mini-transcribe"
        },
        turn_detection: {
          type: "server_vad",
          threshold: 0.6,
          prefix_padding_ms: 300,
          silence_duration_ms: 800
        }
      }
    }

    dataChannel.send(JSON.stringify(sessionUpdate))

    // ×”×•×“×¢×ª ×¤×ª×™×—×” ××”×œ×§×•×— - ×”AI ×”×•× ×”×œ×§×•×—!
    setTimeout(() => {
      const openingMessage = {
        type: "response.create",
        response: {
          modalities: ["audio"],
          instructions: `âš ï¸ ××ª×” ×”×œ×§×•×—, ×œ× ××™×© ×”××›×™×¨×•×ª!
×¤×ª×— ××ª ×”×©×™×—×” ×›×œ×§×•×— ×©××ª×§×©×¨ ×œ×—×‘×¨×”. ×××•×¨ ××©×”×• ×›××•:
"×©×œ×•×, ×©××™ ${persona?.persona_name || '×“× ×™'}, ×× ×™ ××ª×§×©×¨ ×›×™ ×¨××™×ª×™ ××ª ×”×¤×¨×¡×•× ×©×œ×›× ×•×¨×¦×™×ª×™ ×œ×©××•×¢ ×¢×•×“..."
××•: "×”×™×™, ×× ×™ ××—×¤×© ×¤×ª×¨×•×Ÿ ×œ... ××™×©×”×• ×”××œ×™×¥ ×œ×™ ×¢×œ×™×›×"
ğŸš« ××œ ×ª×©××œ "××™×š ××•×›×œ ×œ×¢×–×•×¨ ×œ×š" - ×–×” ××©×¤×˜ ×©×œ ××™×© ×©×™×¨×•×ª, ×•××ª×” ×”×œ×§×•×—!`
        }
      }
      dataChannel.send(JSON.stringify(openingMessage))
    }, 1000)
  }

  // ×¡×™×•× ×”×¡×™××•×œ×¦×™×”
  // ×¢×¦×™×¨×” ××™×™×“×™×ª ×œ×œ× ×©××™×¨×”
  const stopSimulation = () => {
    try {
      setStatus('ending')
      
      // × ×™×ª×•×§ ×”×—×™×‘×•×¨×™×
      if (mediaStream) {
        mediaStream.getTracks().forEach(track => track.stop())
      }
      if (peerConnection) {
        peerConnection.close()
      }
      
      // ×—×–×•×¨ ×œ×¢××•×“ ×”×¡×™××•×œ×¦×™×•×ª
      router.push('/simulations')
    } catch (error) {
      console.error('âŒ ×©×’×™××” ×‘×¢×¦×™×¨×ª ×¡×™××•×œ×¦×™×”:', error)
      setStatus('error')
    }
  }

  // ×¢×¦×™×¨×” ×•×©×œ×™×—×” ×œ× ×™×ª×•×—
  const endSimulation = async () => {
    try {
      setStatus('ending')
      
      // × ×™×ª×•×§ ×”×—×™×‘×•×¨×™×
      if (mediaStream) {
        mediaStream.getTracks().forEach(track => track.stop())
      }
      if (peerConnection) {
        peerConnection.close()
      }

      // ×©××™×¨×ª ×ª×•×¦××•×ª ×”×¡×™××•×œ×¦×™×” ×¢× ×‘×§×©×” ×œ× ×™×ª×•×—
      const response = await fetch('/api/simulations/complete', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          simulationId: simulation.id,
          transcript: transcript.join('\n'),
          metrics: simulationMetrics,
          status: 'completed',
          generateReport: true // ×“×’×œ ×œ×™×™×¦×•×¨ ×“×•×—
        })
      })

      if (response.ok) {
        const result = await response.json()
        setStatus('completed')
        
        // ××¢×‘×¨ ×œ×¢××•×“ ×”×“×•×—
        setTimeout(() => {
          if (result.reportId) {
            router.push(`/simulations/report/${result.reportId}`)
          } else {
            router.push(`/simulations/report/${simulation.id}`)
          }
        }, 2000)
      } else {
        throw new Error('Failed to complete simulation')
      }

    } catch (error) {
      console.error('âŒ ×©×’×™××” ×‘×¡×™×•× ×•× ×™×ª×•×— ×¡×™××•×œ×¦×™×”:', error)
      setStatus('error')
    }
  }

  // ×¤×¢×•×œ×•×ª ×××©×§
  const handleStartSimulation = async () => {
    try {
      setIsAudioEnabled(true)
      await initializeWebRTC()
    } catch (error) {
      setIsAudioEnabled(false)
      setStatus('error')
    }
  }

  return (
    <div className="max-w-4xl mx-auto p-6 space-y-6">
      {/* ×›×•×ª×¨×ª */}
      <div className="bg-white rounded-xl shadow-lg p-6">
        <div className="flex justify-between items-start mb-4">
          <div>
            <h1 className="text-2xl font-bold text-gray-900 mb-2">
              ğŸ¯ ×¡×™××•×œ×¦×™×” ×‘×–××Ÿ ×××ª
            </h1>
            <p className="text-gray-600">
              ××™××•×Ÿ ×¢× {persona?.persona_name || '×œ×§×•×— ×•×•×™×¨×˜×•××œ×™'} â€¢ 
              ×¨××ª ×§×•×©×™: {simulation.difficulty_level}
            </p>
          </div>
          
          <div className="text-center">
            <div className={`inline-flex items-center px-3 py-1 rounded-full text-sm font-medium ${
              status === 'active' ? 'bg-green-100 text-green-800' :
              status === 'ready' ? 'bg-blue-100 text-blue-800' :
              status === 'ending' ? 'bg-orange-100 text-orange-800' :
              status === 'error' ? 'bg-red-100 text-red-800' :
              'bg-gray-100 text-gray-800'
            }`}>
              <div className={`w-2 h-2 rounded-full mr-2 ${
                status === 'active' ? 'bg-green-500 animate-pulse' :
                status === 'ready' ? 'bg-blue-500' :
                status === 'ending' ? 'bg-orange-500 animate-pulse' :
                status === 'error' ? 'bg-red-500' :
                'bg-gray-500'
              }`} />
              {status === 'preparing' && '××›×™×Ÿ...'}
              {status === 'connecting' && '××ª×—×‘×¨...'}
              {status === 'ready' && '××•×›×Ÿ ×œ×”×ª×—×™×œ'}
              {status === 'active' && '×©×™×—×” ×¤×¢×™×œ×”'}
              {status === 'ending' && '××¡×™×™×...'}
              {status === 'completed' && '×”×•×©×œ×'}
              {status === 'error' && '×©×’×™××”'}
            </div>
          </div>
        </div>

        {/* ×¤×¨×˜×™ ×”×œ×§×•×— */}
        <div className="bg-blue-50 rounded-lg p-4">
          <h3 className="font-medium text-blue-900 mb-2">×¤×¨×•×¤×™×œ ×”×œ×§×•×—:</h3>
          <div className="grid grid-cols-1 md:grid-cols-2 gap-4 text-sm">
            <div>
              <span className="font-medium">×¡×•×’ ××™×©×™×•×ª:</span> {persona?.personality_type}
            </div>
            <div>
              <span className="font-medium">×¡×’× ×•×Ÿ ×ª×§×©×•×¨×ª:</span> {persona?.communication_style}
            </div>
          </div>
          <p className="text-blue-700 text-sm mt-2">
            {persona?.current_situation}
          </p>
        </div>
      </div>

      {/* ×‘×§×¨×•×ª */}
      <div className="bg-white rounded-xl shadow-lg p-6">
        <div className="flex justify-center space-x-4">
          {!isAudioEnabled && status === 'preparing' && (
            <button
              onClick={handleStartSimulation}
              className="bg-blue-600 text-white px-6 py-3 rounded-lg font-medium hover:bg-blue-700 transition-colors"
            >
              ğŸ¤ ×”×ª×—×œ ×¡×™××•×œ×¦×™×”
            </button>
          )}

          {status === 'active' && (
            <div className="flex space-x-3">
              <button
                onClick={stopSimulation}
                className="bg-gray-600 text-white px-6 py-3 rounded-lg font-medium hover:bg-gray-700 transition-colors flex items-center"
              >
                â¹ï¸ ×¢×¦×•×¨ ×¡×™××•×œ×¦×™×”
              </button>
              <button
                onClick={endSimulation}
                className="bg-red-600 text-white px-6 py-3 rounded-lg font-medium hover:bg-red-700 transition-colors flex items-center"
              >
                ğŸ ×¢×¦×•×¨ ×•×©×œ×— ×œ× ×™×ª×•×—
              </button>
            </div>
          )}

          {status === 'error' && (
            <button
              onClick={() => window.location.reload()}
              className="bg-gray-600 text-white px-6 py-3 rounded-lg font-medium hover:bg-gray-700 transition-colors"
            >
              ğŸ”„ × ×¡×” ×©×•×‘
            </button>
          )}
        </div>

        {status === 'connecting' && (
          <div className="text-center mt-4">
            <div className="animate-spin w-8 h-8 border-4 border-blue-600 border-t-transparent rounded-full mx-auto mb-2"></div>
            <p className="text-gray-600">××ª×—×‘×¨ ×œ-OpenAI Realtime API...</p>
          </div>
        )}
      </div>

      {/* ×ª××œ×•×œ ×‘×–××Ÿ ×××ª */}
      {(status === 'active' || status === 'completed') && (
        <div className="bg-white rounded-xl shadow-lg p-6">
          <h3 className="text-lg font-bold text-gray-900 mb-4">
            ğŸ’¬ ×ª××œ×•×œ ×”×©×™×—×”
          </h3>
          
          <div className="h-64 overflow-y-auto border rounded-lg p-4 bg-gray-50 space-y-2">
            {transcript.map((message, index) => (
              <div key={index} className={`p-2 rounded ${
                message.startsWith('ğŸ‘¤') ? 'bg-blue-100 text-blue-900' : 'bg-green-100 text-green-900'
              }`}>
                {message}
              </div>
            ))}
            
            {currentMessage && (
              <div className="p-2 rounded bg-green-100 text-green-900 opacity-70">
                ğŸ¤– {persona?.persona_name || '×œ×§×•×—'}: {currentMessage}...
              </div>
            )}
            
            {transcript.length === 0 && status === 'active' && (
              <div className="text-center text-gray-500 py-8">
                <p>××ª×—×™×œ ×©×™×—×”...</p>
              </div>
            )}
          </div>
        </div>
      )}

      {/* ××˜×¨×™×§×•×ª ×‘×–××Ÿ ×××ª */}
      {status === 'active' && simulationMetrics.startTime && (
        <div className="bg-white rounded-xl shadow-lg p-6">
          <h3 className="text-lg font-bold text-gray-900 mb-4">
            ğŸ“Š ××“×“×™ ×‘×™×¦×•×¢×™×
          </h3>
          
          <div className="grid grid-cols-2 md:grid-cols-4 gap-4">
            <div className="text-center">
              <div className="text-2xl font-bold text-blue-600">
                {Math.floor((Date.now() - simulationMetrics.startTime.getTime()) / 1000 / 60)}
              </div>
              <div className="text-sm text-gray-600">×“×§×•×ª</div>
            </div>
            
            <div className="text-center">
              <div className="text-2xl font-bold text-green-600">
                {transcript.filter(t => t.startsWith('ğŸ‘¤')).length}
              </div>
              <div className="text-sm text-gray-600">×ª×’×•×‘×•×ª ×©×œ×š</div>
            </div>
            
            <div className="text-center">
              <div className="text-2xl font-bold text-purple-600">
                {transcript.filter(t => t.startsWith('ğŸ¤–')).length}
              </div>
              <div className="text-sm text-gray-600">×ª×’×•×‘×•×ª ×œ×§×•×—</div>
            </div>
            
            <div className="text-center">
              <div className="text-2xl font-bold text-orange-600">
                {simulationMetrics.interruptionsCount}
              </div>
              <div className="text-sm text-gray-600">×”×¤×¨×¢×•×ª</div>
            </div>
          </div>
        </div>
      )}

      {/* ×”×•×“×¢×•×ª ××¦×‘ */}
      {status === 'completed' && (
        <div className="bg-green-50 border border-green-200 rounded-xl p-6 text-center">
          <div className="text-4xl mb-4">ğŸ‰</div>
          <h3 className="text-xl font-bold text-green-900 mb-2">
            ×¡×™××•×œ×¦×™×” ×”×•×©×œ××” ×‘×”×¦×œ×—×”!
          </h3>
          <p className="text-green-700">
            ××¢×‘×™×¨ ××•×ª×š ×œ×“×•×— ×”××¤×•×¨×˜...
          </p>
        </div>
      )}

      {status === 'error' && (
        <div className="bg-red-50 border border-red-200 rounded-xl p-6 text-center">
          <div className="text-4xl mb-4">âŒ</div>
          <h3 className="text-xl font-bold text-red-900 mb-2">
            ×©×’×™××” ×‘×¡×™××•×œ×¦×™×”
          </h3>
          <p className="text-red-700">
            ×× × × ×¡×” ×©×•×‘ ××• ×¦×•×¨ ×§×©×¨ ×¢× ×”×ª××™×›×”
          </p>
        </div>
      )}
    </div>
  )
}
