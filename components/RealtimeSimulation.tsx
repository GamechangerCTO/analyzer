'use client'

import { useState, useEffect, useRef } from 'react'
import { useRouter } from 'next/navigation'
import { createBaseSystemPrompt, getOptimalPrompt, type SimulationPromptParams } from '@/lib/simulation-prompts'

interface RealtimeSimulationProps {
  simulation: any
  customerPersona?: any
  user: any
  company: any
}

type SimulationStatus = 'preparing' | 'connecting' | 'ready' | 'active' | 'ending' | 'completed' | 'error'

export default function RealtimeSimulation({ simulation, customerPersona, user, company }: RealtimeSimulationProps) {
  const router = useRouter()
  const [status, setStatus] = useState<SimulationStatus>('preparing')
  const [isAudioEnabled, setIsAudioEnabled] = useState(false)
  const [transcript, setTranscript] = useState<string[]>([])
  const [audioContext, setAudioContext] = useState<AudioContext | null>(null)
  const [mediaStream, setMediaStream] = useState<MediaStream | null>(null)
  const [peerConnection, setPeerConnection] = useState<RTCPeerConnection | null>(null)
  const [dataChannel, setDataChannel] = useState<RTCDataChannel | null>(null)
  const [sessionStarted, setSessionStarted] = useState(false)
  const [currentMessage, setCurrentMessage] = useState('')
  const [simulationMetrics, setSimulationMetrics] = useState({
    startTime: null as Date | null,
    responseTime: 0,
    interruptionsCount: 0,
    currentObjection: null as string | null
  })

  const audioElementRef = useRef<HTMLAudioElement | null>(null)
  const ephemeralKeyRef = useRef<string | null>(null)

  // ×”×’×“×¨×ª ×¤×¨×¡×•× ×ª ×”×œ×§×•×— ×œ-AI (×§×‘×œ×ª ×”×¤×¨×¡×•× ×” ××”×¤×¨××˜×¨ ××• ××”×¡×™××•×œ×¦×™×”)
  const persona = customerPersona || simulation.customer_personas_hebrew?.[0]
  
  // ×§×‘×™×¢×ª ×§×•×œ ×‘×”×ª×× ×œ×¤×¨×¡×•× ×”
  const getVoiceForPersona = () => {
    // ×‘×“×™×§×” ×× ×™×© ×”×’×“×¨×” ×¡×¤×¦×™×¤×™×ª ×‘×¤×¨×¡×•× ×”
    if (persona?.voice_characteristics?.gender) {
      if (persona.voice_characteristics.gender === 'male' || persona.voice_characteristics.gender === '×–×›×¨') {
        return 'echo' // ×§×•×œ ×’×‘×¨×™
      } else {
        return 'shimmer' // ×§×•×œ × ×©×™
      }
    }
    
    // ×‘×“×™×§×” ×œ×¤×™ ×©× ×”×¤×¨×¡×•× ×”
    const personaName = persona?.persona_name || ''
    const maleNames = ['×“× ×™', '×××™×¨', '×™×•×¡×™', '×“×•×“', '××™×›××œ', '×¨×•×Ÿ', '××‘×™', '×’×™×œ', '×™×•× ×ª×Ÿ', '××™×ª××¨', '×™×¢×§×‘', '××©×”', '××‘×¨×”×', '×™×¦×—×§', '××”×¨×•×Ÿ', '×©××•××œ', '×‘× ×™××™×Ÿ', '××œ×™×¢×–×¨', '×™×”×•×©×¢', '×—×™×™×']
    const femaleNames = ['×“× ×”', '××™×›×œ', '×©×¨×”', '×¨×•×ª×™', '×œ×™××ª', '× ×•×¢×”', '×ª××¨', '×¢× ×ª', '×¨×•× ×™×ª', '×™×¢×œ']
    
    if (maleNames.some(name => personaName.includes(name))) {
      return 'echo' // ×§×•×œ ×’×‘×¨×™
    } else if (femaleNames.some(name => personaName.includes(name))) {
      return 'shimmer' // ×§×•×œ × ×©×™
    }
    
    // ×‘×¨×™×¨×ª ××—×“×œ - × ×§×‘×” (×›×™ ×¨×•×‘ ×¤×¨×¡×•× ×•×ª ×”×œ×§×•×—×•×ª × ×©×™× ×‘× ×™×¡×™×•×Ÿ ×©×œ×™)
    return 'shimmer'
  }

  const createAIInstructions = () => {
    const isGenderMale = getVoiceForPersona() === 'echo'
    const genderText = isGenderMale ? '×œ×§×•×— ×¤×•×˜× ×¦×™××œ×™' : '×œ×§×•×—×” ×¤×•×˜× ×¦×™××œ×™×ª'
    
    // ××™×œ×™× ×“×™× ××™×•×ª ×œ×¤×™ ××’×“×¨
    const pronouns = {
      you: isGenderMale ? '××ª×”' : '××ª',
      howYouSpeak: isGenderMale ? '××™×š ××ª×” ××“×‘×¨' : '××™×š ××ª ××“×‘×¨×ª',
      speak: isGenderMale ? '××“×‘×¨' : '××“×‘×¨×ª', 
      use: isGenderMale ? '××©×ª××©' : '××©×ª××©×ª',
      beReal: isGenderMale ? '×ª×”×™×” ×××™×ª×™' : '×ª×”×™×™ ×××™×ª×™×ª',
      customer: isGenderMale ? '×œ×§×•×—' : '×œ×§×•×—×”',
      ask: isGenderMale ? '×ª×©××œ' : '×ª×©××œ×™',
      say: isGenderMale ? '×ª×’×™×“' : '×ª×’×™×“×™',
      raise: isGenderMale ? '×ª×¢×œ×”' : '×ª×¢×œ×™',
      let: isGenderMale ? '×ª×Ÿ' : '×ª× ×™',
      be: isGenderMale ? '×ª×”×™×”' : '×ª×”×™×™',
      agree: isGenderMale ? '×ª×¡×›×™×' : '×ª×¡×›×™××™',
      useFillers: isGenderMale ? '×”×©×ª××©' : '×”×©×ª××©×™',
      dontBe: isGenderMale ? '××œ ×ª×”×™×”' : '××œ ×ª×”×™×™',
      dontSay: isGenderMale ? '××œ ×ª×’×™×“' : '××œ ×ª×’×™×“×™',
      dontUse: isGenderMale ? '××œ ×ª×©×ª××©' : '××œ ×ª×©×ª××©×™',
      dontGiveIn: isGenderMale ? '××œ ×ª×™×›× ×¢' : '××œ ×ª×›× ×¢×™',
      start: isGenderMale ? '×ª×ª×—×™×œ' : '×ª×ª×—×™×œ×™',
      called: isGenderMale ? '×”×ª×§×©×¨×ª' : '×”×ª×§×©×¨×ª'
    }

    const instructions = `
${pronouns.you} ${persona?.persona_name || '×“× ×”'} - ${genderText} ×××™×ª×™ ×©××ª×§×©×¨ ×œ×—×‘×¨×”.

×¨×§×¢ ××™×©×™: ${persona?.background_story || '××× ×œ×©× ×™ ×™×œ×“×™×, ×¢×•×‘×“×ª ×‘×—×‘×¨×ª ×”×™×™×˜×§, ××•×”×‘×ª ×œ×§× ×•×ª ×“×‘×¨×™× ××™×›×•×ª×™×™× ××‘×œ ××§×¤×™×“×” ×¢×œ ×”××—×™×¨'}

×”××¦×‘ ×©×œ×š ×¢×›×©×™×•: ${persona?.current_situation || '×©××¢×ª ×¢×œ ×”×—×‘×¨×” ××—×‘×¨×” ×˜×•×‘×” ×•×¨×•×¦×” ×œ×‘×“×•×§ ×× ×–×” ××ª××™× ×œ×š'}

${pronouns.howYouSpeak}:
- ×‘×¦×•×¨×” × ×•×¨××œ×™×ª ×•×™×©×™×¨×”, ×›××• ×›×œ ××—×“ ×××ª× ×•
- ${pronouns.use} ×‘××™×œ×™× ×›××• "×‘×˜×—", "× ×•", "××•×§×™×™", "×›×Ÿ, ××××"
- ×œ× ×¤×•×¨××œ×™×ª ××“×™ - ×¤×©×•×˜ ×©×™×—×” ×¨×’×™×œ×”
- ${persona?.communication_style || '×™×“×™×“×•×ª×™×ª ××‘×œ ×–×”×™×¨×” ×¢× ×”×›×¡×£'}

×”×‘×¢×™×•×ª ×©×œ×š ×¢× ×§× ×™×•×ª:
${persona?.common_objections?.join('\n') || '×”××—×™×¨ × ×©××¢ ×™×§×¨ ×‘×©×‘×™×œ ××” ×©×× ×™ ××§×‘×œ×ª\n×× ×™ ×œ× ×‘×˜×•×—×” ×©×–×” ×‘×××ª ×™×¢×‘×•×“ ×‘×©×‘×™×œ×™\n××•×œ×™ ×™×© ××©×”×• ×“×•××” ×™×•×ª×¨ ×–×•×œ?'}

××™×š ×œ×”×ª× ×”×’ ×‘×©×™×—×”:
âœ… ${pronouns.beReal} - ×›××• ×©×›×œ ${pronouns.customer} ${pronouns.speak}
âœ… ${pronouns.ask} ×©××œ×•×ª ×›××•: "×›××” ×–×” ×¢×•×œ×”?", "××™×š ×–×” ×¢×•×‘×“?", "××” ×× ×–×” ×œ× ×™×ª××™× ×œ×™?"
âœ… ${pronouns.say} ×“×‘×¨×™× ×›××•: "×‘×˜×—, × ×©××¢ ××¢× ×™×™×Ÿ ××‘×œ...", "×¨×’×¢, ×× ×™ ×œ× ××‘×™× ×”..."
âœ… ${pronouns.raise} ×”×ª× ×’×“×•×™×•×ª ×‘××•×¤×Ÿ ×˜×‘×¢×™ ×‘××”×œ×š ×”×©×™×—×”
âœ… ${pronouns.let} ×œ× ×¦×™×’ ×œ×”×¡×‘×™×¨ ×œ×¤× ×™ ×©×ª×’×™×‘
âœ… ${pronouns.be} × ×—××“ ××‘×œ ×œ× ${pronouns.agree} ××”×¨
âœ… ${pronouns.useFillers} ×‘××™×œ×•×ª ××™×œ×•×™ ×›××• "××××", "×‘×§×™×¦×•×¨", "× ×•"

âŒ ${pronouns.dontBe} ×¨×•×‘×•×˜!
âŒ ${pronouns.dontSay} "×× ×™ ××‘×™× ×”" ×›×œ ×”×–××Ÿ
âŒ ${pronouns.dontUse} ×‘××™×œ×™× ×¤×•×¨××œ×™×•×ª
âŒ ${pronouns.dontGiveIn} ××”×¨ ××“×™

×”××˜×¨×”: ×œ×¢×–×•×¨ ×œ× ×¦×™×’ ×œ×”×ª×××Ÿ ×¢×œ ×©×™×—×ª ××›×™×¨×” ×××™×ª×™×ª ××™×ª×š.
${pronouns.start} ×‘×œ×”×’×™×“ ×©×œ×•× ×•×ª×’×™×“ ×œ××” ${pronouns.called} ×‘×§×¦×¨×”.
`

    return instructions
  }

  // ×§×‘×œ×ª ephemeral token ××”×©×¨×ª
  const getEphemeralToken = async () => {
    try {
      setStatus('connecting')
      const response = await fetch('/api/simulations/ephemeral-token', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ 
          simulationId: simulation.id,
          instructions: createAIInstructions(),
          voice: getVoiceForPersona()
        })
      })

      if (!response.ok) {
        throw new Error('Failed to get ephemeral token')
      }

      const data = await response.json()
      ephemeralKeyRef.current = data.client_secret?.value
      
      if (!ephemeralKeyRef.current) {
        throw new Error('No ephemeral token received')
      }

      return ephemeralKeyRef.current
    } catch (error) {
      console.error('Error getting ephemeral token:', error)
      setStatus('error')
      throw error
    }
  }

  // ×”×’×“×¨×ª WebRTC connection
  const initializeWebRTC = async () => {
    try {
      if (!ephemeralKeyRef.current) {
        await getEphemeralToken()
      }

      // ×™×¦×™×¨×ª peer connection
      const pc = new RTCPeerConnection({
        iceServers: [{ urls: 'stun:stun.l.google.com:19302' }]
      })

      // ×”×’×“×¨×ª audio element ×œ×§×‘×œ×ª ××•×“×™×• ××”-AI
      if (!audioElementRef.current) {
        const audioEl = document.createElement('audio')
        audioEl.autoplay = true
        audioEl.setAttribute('playsinline', 'true')
        audioElementRef.current = audioEl
      }

      pc.ontrack = (event) => {
        if (audioElementRef.current) {
          audioElementRef.current.srcObject = event.streams[0]
        }
      }

      // ×§×‘×œ×ª microphone ××”××©×ª××©
      const mediaStream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 16000
        } 
      })
      
      setMediaStream(mediaStream)
      pc.addTrack(mediaStream.getTracks()[0])

      // ×™×¦×™×¨×ª data channel ×œ×¢×“×›×•× ×™×
      const dc = pc.createDataChannel('oai-events')
      setDataChannel(dc)

      dc.onopen = () => {
        console.log('ğŸ¯ Data channel × ×¤×ª×— - ××•×›×Ÿ ×œ×ª×§×©×•×¨×ª')
        setStatus('ready')
      }

      dc.onmessage = (event) => {
        try {
          const serverEvent = JSON.parse(event.data)
          handleServerEvent(serverEvent)
        } catch (error) {
          console.error('Error parsing server event:', error)
        }
      }

      // ×™×¦×™×¨×ª SDP offer
      const offer = await pc.createOffer()
      await pc.setLocalDescription(offer)

      // ×©×œ×™×—×” ×œOpenAI Realtime API
      const baseUrl = "https://api.openai.com/v1/realtime/calls"
      const model = "gpt-realtime"
      
      console.log('ğŸ”‘ Ephemeral token:', ephemeralKeyRef.current?.substring(0, 20) + '...')
      console.log('ğŸ“¡ Sending SDP offer to:', `${baseUrl}?model=${model}`)
      
      const sdpResponse = await fetch(`${baseUrl}?model=${model}`, {
        method: "POST",
        body: offer.sdp,
        headers: {
          Authorization: `Bearer ${ephemeralKeyRef.current}`,
          "Content-Type": "application/sdp",
          "OpenAI-Beta": "realtime=v1"
        },
      })

      if (!sdpResponse.ok) {
        const errorText = await sdpResponse.text()
        console.error('ğŸ”´ SDP request failed:', {
          status: sdpResponse.status,
          statusText: sdpResponse.statusText,
          error: errorText,
          headers: Object.fromEntries(sdpResponse.headers.entries())
        })
        throw new Error(`SDP request failed: ${sdpResponse.status} - ${errorText}`)
      }

      const answer = {
        type: "answer" as RTCSdpType,
        sdp: await sdpResponse.text(),
      }
      
      await pc.setRemoteDescription(answer)
      
      setPeerConnection(pc)
      console.log('âœ… WebRTC connection ×”×•×§× ×‘×”×¦×œ×—×”')

    } catch (error) {
      console.error('âŒ ×©×’×™××” ×‘×”×§××ª WebRTC:', error)
      setStatus('error')
      throw error
    }
  }

  // ×˜×™×¤×•×œ ×‘××™×¨×•×¢×™ ×”×©×¨×ª
  const handleServerEvent = (event: any) => {
    console.log('ğŸ“¨ Server event:', event.type, event)

    switch (event.type) {
      case 'session.created':
        console.log('ğŸ‰ ×¡×©×Ÿ × ×•×¦×¨ ×‘×”×¦×œ×—×”')
        console.log('ğŸ“Š dataChannel ×–××™×Ÿ:', !!dataChannel)
        console.log('ğŸ“Š sessionStarted:', sessionStarted)
        startSimulation()
        break

      case 'response.audio_transcript.delta':
        if (event.delta) {
          setCurrentMessage(prev => prev + event.delta)
        }
        break

                case 'response.audio_transcript.done':
        if (event.transcript) {
          setTranscript(prev => [...prev, `ğŸ¤– ${persona?.persona_name || '×œ×§×•×—'}: ${event.transcript}`])
          setCurrentMessage('')
        }
        break

      case 'input_audio_buffer.speech_started':
        console.log('ğŸ¤ ×”× ×¦×™×’ ×”×ª×—×™×œ ×œ×“×‘×¨')
        setSimulationMetrics(prev => ({
          ...prev,
          responseTime: Date.now()
        }))
        break

      case 'input_audio_buffer.speech_stopped':
        console.log('ğŸ”‡ ×”× ×¦×™×’ ×”×¤×¡×™×§ ×œ×“×‘×¨')
        break

      case 'conversation.item.input_audio_transcription.completed':
        if (event.transcript) {
          setTranscript(prev => [...prev, `ğŸ‘¤ ××ª×”: ${event.transcript}`])
        }
        break

      case 'error':
        console.error('âŒ ×©×’×™××” ××”×©×¨×ª:', event)
        setStatus('error')
        break

      default:
        // ××™×¨×•×¢×™× × ×•×¡×¤×™×...
        break
    }
  }

  // ×”×ª×—×œ×ª ×”×¡×™××•×œ×¦×™×”
  const startSimulation = () => {
    console.log('ğŸš€ ××ª×—×™×œ ×¡×™××•×œ×¦×™×”, dataChannel:', !!dataChannel)
    if (!dataChannel) {
      console.error('âŒ ××™×Ÿ dataChannel - ×œ× ×™×›×•×œ ×œ×”×ª×—×™×œ ×¡×™××•×œ×¦×™×”')
      return
    }

    console.log('âœ… ××¢×“×›×Ÿ ×¡×˜×˜×•×¡ ×œ-active')
    setStatus('active')
    setSessionStarted(true)
    setSimulationMetrics(prev => ({
      ...prev,
      startTime: new Date()
    }))

    // ×”×’×“×¨×ª session ×¢× ×”×”×•×¨××•×ª
    const sessionUpdate = {
      type: "session.update",
      session: {
        type: "realtime",
        model: "gpt-realtime",
        modalities: ["text", "audio"],
        instructions: createAIInstructions(),
        voice: getVoiceForPersona(),
        input_audio_format: "pcm16",
        output_audio_format: "pcm16",
        input_audio_transcription: {
          model: "whisper-1"
        },
        turn_detection: {
          type: "server_vad",
          threshold: 0.6,
          prefix_padding_ms: 300,
          silence_duration_ms: 800
        }
      }
    }

    dataChannel.send(JSON.stringify(sessionUpdate))

    // ×”×•×“×¢×ª ×¤×ª×™×—×” ××”×œ×§×•×—
    setTimeout(() => {
              const openingMessage = {
          type: "response.create",
          response: {
            modalities: ["audio"],
            instructions: `×ª×ª×—×™×œ ××ª ×”×©×™×—×” ×¢× ×”× ×¦×™×’. ×ª×›×™×¨ ××ª ×¢×¦××š ×›${persona?.persona_name || '×œ×§×•×— ×¤×•×˜× ×¦×™××œ×™'} ×•×ª×‘×™×¢ ×¢× ×™×™×Ÿ ×¨××©×•× ×™ ×‘××•×¦×¨/×©×™×¨×•×ª. ×”×™×” ×—×‘×¨×•×ª×™ ××‘×œ ×–×”×™×¨.`
          }
        }
      dataChannel.send(JSON.stringify(openingMessage))
    }, 1000)
  }

  // ×¡×™×•× ×”×¡×™××•×œ×¦×™×”
  // ×¢×¦×™×¨×” ××™×™×“×™×ª ×œ×œ× ×©××™×¨×”
  const stopSimulation = () => {
    try {
      setStatus('ending')
      
      // × ×™×ª×•×§ ×”×—×™×‘×•×¨×™×
      if (mediaStream) {
        mediaStream.getTracks().forEach(track => track.stop())
      }
      if (peerConnection) {
        peerConnection.close()
      }
      
      // ×—×–×•×¨ ×œ×¢××•×“ ×”×¡×™××•×œ×¦×™×•×ª
      router.push('/simulations')
    } catch (error) {
      console.error('âŒ ×©×’×™××” ×‘×¢×¦×™×¨×ª ×¡×™××•×œ×¦×™×”:', error)
      setStatus('error')
    }
  }

  // ×¢×¦×™×¨×” ×•×©×œ×™×—×” ×œ× ×™×ª×•×—
  const endSimulation = async () => {
    try {
      setStatus('ending')
      
      // × ×™×ª×•×§ ×”×—×™×‘×•×¨×™×
      if (mediaStream) {
        mediaStream.getTracks().forEach(track => track.stop())
      }
      if (peerConnection) {
        peerConnection.close()
      }

      // ×©××™×¨×ª ×ª×•×¦××•×ª ×”×¡×™××•×œ×¦×™×” ×¢× ×‘×§×©×” ×œ× ×™×ª×•×—
      const response = await fetch('/api/simulations/complete', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          simulationId: simulation.id,
          transcript: transcript.join('\n'),
          metrics: simulationMetrics,
          status: 'completed',
          generateReport: true // ×“×’×œ ×œ×™×™×¦×•×¨ ×“×•×—
        })
      })

      if (response.ok) {
        const result = await response.json()
        setStatus('completed')
        
        // ××¢×‘×¨ ×œ×¢××•×“ ×”×“×•×—
        setTimeout(() => {
          if (result.reportId) {
            router.push(`/simulations/report/${result.reportId}`)
          } else {
            router.push(`/simulations/report/${simulation.id}`)
          }
        }, 2000)
      } else {
        throw new Error('Failed to complete simulation')
      }

    } catch (error) {
      console.error('âŒ ×©×’×™××” ×‘×¡×™×•× ×•× ×™×ª×•×— ×¡×™××•×œ×¦×™×”:', error)
      setStatus('error')
    }
  }

  // ×¤×¢×•×œ×•×ª ×××©×§
  const handleStartSimulation = async () => {
    try {
      setIsAudioEnabled(true)
      await initializeWebRTC()
    } catch (error) {
      setIsAudioEnabled(false)
      setStatus('error')
    }
  }

  return (
    <div className="max-w-4xl mx-auto p-6 space-y-6">
      {/* ×›×•×ª×¨×ª */}
      <div className="bg-white rounded-xl shadow-lg p-6">
        <div className="flex justify-between items-start mb-4">
          <div>
            <h1 className="text-2xl font-bold text-gray-900 mb-2">
              ğŸ¯ ×¡×™××•×œ×¦×™×” ×‘×–××Ÿ ×××ª
            </h1>
            <p className="text-gray-600">
              ××™××•×Ÿ ×¢× {persona?.persona_name || '×œ×§×•×— ×•×•×™×¨×˜×•××œ×™'} â€¢ 
              ×¨××ª ×§×•×©×™: {simulation.difficulty_level}
            </p>
          </div>
          
          <div className="text-center">
            <div className={`inline-flex items-center px-3 py-1 rounded-full text-sm font-medium ${
              status === 'active' ? 'bg-green-100 text-green-800' :
              status === 'ready' ? 'bg-blue-100 text-blue-800' :
              status === 'ending' ? 'bg-orange-100 text-orange-800' :
              status === 'error' ? 'bg-red-100 text-red-800' :
              'bg-gray-100 text-gray-800'
            }`}>
              <div className={`w-2 h-2 rounded-full mr-2 ${
                status === 'active' ? 'bg-green-500 animate-pulse' :
                status === 'ready' ? 'bg-blue-500' :
                status === 'ending' ? 'bg-orange-500 animate-pulse' :
                status === 'error' ? 'bg-red-500' :
                'bg-gray-500'
              }`} />
              {status === 'preparing' && '××›×™×Ÿ...'}
              {status === 'connecting' && '××ª×—×‘×¨...'}
              {status === 'ready' && '××•×›×Ÿ ×œ×”×ª×—×™×œ'}
              {status === 'active' && '×©×™×—×” ×¤×¢×™×œ×”'}
              {status === 'ending' && '××¡×™×™×...'}
              {status === 'completed' && '×”×•×©×œ×'}
              {status === 'error' && '×©×’×™××”'}
            </div>
          </div>
        </div>

        {/* ×¤×¨×˜×™ ×”×œ×§×•×— */}
        <div className="bg-blue-50 rounded-lg p-4">
          <h3 className="font-medium text-blue-900 mb-2">×¤×¨×•×¤×™×œ ×”×œ×§×•×—:</h3>
          <div className="grid grid-cols-1 md:grid-cols-2 gap-4 text-sm">
            <div>
              <span className="font-medium">×¡×•×’ ××™×©×™×•×ª:</span> {persona?.personality_type}
            </div>
            <div>
              <span className="font-medium">×¡×’× ×•×Ÿ ×ª×§×©×•×¨×ª:</span> {persona?.communication_style}
            </div>
          </div>
          <p className="text-blue-700 text-sm mt-2">
            {persona?.current_situation}
          </p>
        </div>
      </div>

      {/* ×‘×§×¨×•×ª */}
      <div className="bg-white rounded-xl shadow-lg p-6">
        <div className="flex justify-center space-x-4">
          {!isAudioEnabled && status === 'preparing' && (
            <button
              onClick={handleStartSimulation}
              className="bg-blue-600 text-white px-6 py-3 rounded-lg font-medium hover:bg-blue-700 transition-colors"
            >
              ğŸ¤ ×”×ª×—×œ ×¡×™××•×œ×¦×™×”
            </button>
          )}

          {status === 'active' && (
            <div className="flex space-x-3">
              <button
                onClick={stopSimulation}
                className="bg-gray-600 text-white px-6 py-3 rounded-lg font-medium hover:bg-gray-700 transition-colors flex items-center"
              >
                â¹ï¸ ×¢×¦×•×¨ ×¡×™××•×œ×¦×™×”
              </button>
              <button
                onClick={endSimulation}
                className="bg-red-600 text-white px-6 py-3 rounded-lg font-medium hover:bg-red-700 transition-colors flex items-center"
              >
                ğŸ ×¢×¦×•×¨ ×•×©×œ×— ×œ× ×™×ª×•×—
              </button>
            </div>
          )}

          {status === 'error' && (
            <button
              onClick={() => window.location.reload()}
              className="bg-gray-600 text-white px-6 py-3 rounded-lg font-medium hover:bg-gray-700 transition-colors"
            >
              ğŸ”„ × ×¡×” ×©×•×‘
            </button>
          )}
        </div>

        {status === 'connecting' && (
          <div className="text-center mt-4">
            <div className="animate-spin w-8 h-8 border-4 border-blue-600 border-t-transparent rounded-full mx-auto mb-2"></div>
            <p className="text-gray-600">××ª×—×‘×¨ ×œ-OpenAI Realtime API...</p>
          </div>
        )}
      </div>

      {/* ×ª××œ×•×œ ×‘×–××Ÿ ×××ª */}
      {(status === 'active' || status === 'completed') && (
        <div className="bg-white rounded-xl shadow-lg p-6">
          <h3 className="text-lg font-bold text-gray-900 mb-4">
            ğŸ’¬ ×ª××œ×•×œ ×”×©×™×—×”
          </h3>
          
          <div className="h-64 overflow-y-auto border rounded-lg p-4 bg-gray-50 space-y-2">
            {transcript.map((message, index) => (
              <div key={index} className={`p-2 rounded ${
                message.startsWith('ğŸ‘¤') ? 'bg-blue-100 text-blue-900' : 'bg-green-100 text-green-900'
              }`}>
                {message}
              </div>
            ))}
            
            {currentMessage && (
              <div className="p-2 rounded bg-green-100 text-green-900 opacity-70">
                ğŸ¤– {persona?.persona_name || '×œ×§×•×—'}: {currentMessage}...
              </div>
            )}
            
            {transcript.length === 0 && status === 'active' && (
              <div className="text-center text-gray-500 py-8">
                <p>××ª×—×™×œ ×©×™×—×”...</p>
              </div>
            )}
          </div>
        </div>
      )}

      {/* ××˜×¨×™×§×•×ª ×‘×–××Ÿ ×××ª */}
      {status === 'active' && simulationMetrics.startTime && (
        <div className="bg-white rounded-xl shadow-lg p-6">
          <h3 className="text-lg font-bold text-gray-900 mb-4">
            ğŸ“Š ××“×“×™ ×‘×™×¦×•×¢×™×
          </h3>
          
          <div className="grid grid-cols-2 md:grid-cols-4 gap-4">
            <div className="text-center">
              <div className="text-2xl font-bold text-blue-600">
                {Math.floor((Date.now() - simulationMetrics.startTime.getTime()) / 1000 / 60)}
              </div>
              <div className="text-sm text-gray-600">×“×§×•×ª</div>
            </div>
            
            <div className="text-center">
              <div className="text-2xl font-bold text-green-600">
                {transcript.filter(t => t.startsWith('ğŸ‘¤')).length}
              </div>
              <div className="text-sm text-gray-600">×ª×’×•×‘×•×ª ×©×œ×š</div>
            </div>
            
            <div className="text-center">
              <div className="text-2xl font-bold text-purple-600">
                {transcript.filter(t => t.startsWith('ğŸ¤–')).length}
              </div>
              <div className="text-sm text-gray-600">×ª×’×•×‘×•×ª ×œ×§×•×—</div>
            </div>
            
            <div className="text-center">
              <div className="text-2xl font-bold text-orange-600">
                {simulationMetrics.interruptionsCount}
              </div>
              <div className="text-sm text-gray-600">×”×¤×¨×¢×•×ª</div>
            </div>
          </div>
        </div>
      )}

      {/* ×”×•×“×¢×•×ª ××¦×‘ */}
      {status === 'completed' && (
        <div className="bg-green-50 border border-green-200 rounded-xl p-6 text-center">
          <div className="text-4xl mb-4">ğŸ‰</div>
          <h3 className="text-xl font-bold text-green-900 mb-2">
            ×¡×™××•×œ×¦×™×” ×”×•×©×œ××” ×‘×”×¦×œ×—×”!
          </h3>
          <p className="text-green-700">
            ××¢×‘×™×¨ ××•×ª×š ×œ×“×•×— ×”××¤×•×¨×˜...
          </p>
        </div>
      )}

      {status === 'error' && (
        <div className="bg-red-50 border border-red-200 rounded-xl p-6 text-center">
          <div className="text-4xl mb-4">âŒ</div>
          <h3 className="text-xl font-bold text-red-900 mb-2">
            ×©×’×™××” ×‘×¡×™××•×œ×¦×™×”
          </h3>
          <p className="text-red-700">
            ×× × × ×¡×” ×©×•×‘ ××• ×¦×•×¨ ×§×©×¨ ×¢× ×”×ª××™×›×”
          </p>
        </div>
      )}
    </div>
  )
}
